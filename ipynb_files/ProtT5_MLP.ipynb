{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46344fd6-26a1-4ccd-a523-9fb5f07efc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装相关依赖库 如果是windows系统，cmd命令框中输入pip安装，参考上述环境配置\n",
    "#!pip install sklearn\n",
    "#!pip install pandas\n",
    "#---------------------------------------------------\n",
    "#导入库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "def allDone():\n",
    "    display(Audio(url='https://www.mediacollege.com/downloads/sound-effects/beep/beep-10.wav', autoplay=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3abc5e-31de-4556-b792-67fdf40c9d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b50e43-058e-4d88-b4e7-35324e75bcd9",
   "metadata": {},
   "source": [
    "## 建立数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f684861d-c3e6-4e9f-9fcf-b5f5016e32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq = pd.read_csv('../data/mode1_for_embed.csv')\n",
    "\n",
    "# add space between each amino aicds\n",
    "protein_seq['wt_seq'] = protein_seq['wt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))\n",
    "protein_seq['mt_seq'] = protein_seq['mt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))\n",
    "\n",
    "protein_seq['label'].astype(str)\n",
    "label_names = set(protein_seq['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b4c5bd-ff89-45bf-b71e-9e1d0e04898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20655\n",
       "1     7095\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1330dd-a4bf-4983-ab36-4aa9caae5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_downstream(embed_path):\n",
    "    path = embed_path + '/'\n",
    "    concat = []\n",
    "    for pkl in os.listdir(path):\n",
    "        if(\".pkl\" in pkl):\n",
    "            file_path = path + pkl\n",
    "            with open(file_path, 'rb') as file:\n",
    "                y = pickle.load(file)\n",
    "                concat += y\n",
    "    data_y = []\n",
    "    data_X = []\n",
    "    for i in range(len(concat)):\n",
    "        data_X.append(concat[i]['x'][0])\n",
    "        data_y.append(int(concat[i]['label']))\n",
    "    data_X = np.array(data_X)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c125368-93a4-4f41-bea4-c3ac8997e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_dataset(situation, gene_constrain, mode):\n",
    "#     if 'gene_balance' in situation:\n",
    "#         mode_train = np.load(f'../data/{gene_constrain}/gene_balance/For_ML/{mode}_train.npy', allow_pickle=True)\n",
    "#         mode_test = np.load(f'../data/{gene_constrain}/gene_balance/For_ML/{mode}_test.npy', allow_pickle=True)\n",
    "        \n",
    "#         X_train = mode_train[:,:-1]\n",
    "#         y_train = mode_train[:,-1].astype(int).tolist()\n",
    "#         X_test = mode_test[:,:-1]\n",
    "#         y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "#         return X_train, y_train, X_test, y_test\n",
    "    \n",
    "#     elif 'gene_not_balance' in situation:\n",
    "#         mode_train = np.load(f'../data/{gene_constrain}/gene_not_balance/For_ML/{mode}_train.npy')\n",
    "#         mode_test = np.load(f'../data/{gene_constrain}/gene_not_balance/For_ML/{mode}_test.npy')\n",
    "        \n",
    "#         X_train = mode_train[:,:-1]\n",
    "#         y_train = mode_train[:,-1].astype(int).tolist()\n",
    "#         X_test = mode_test[:,:-1]\n",
    "#         y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "#         return X_train, y_train, X_test, y_test\n",
    "\n",
    "#     elif 'imbalance' in situation:\n",
    "#         mode_train = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train.npy')\n",
    "#         mode_test = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_test.npy')\n",
    "\n",
    "#         X_train = mode_train[:,:-1]\n",
    "#         y_train = mode_train[:,-1].astype(int).tolist()\n",
    "#         X_test = mode_test[:,:-1]\n",
    "#         y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "#         return X_train, y_train, X_test, y_test\n",
    "    \n",
    "#     else:\n",
    "#         mode_train1 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_1.npy')\n",
    "#         mode_train2 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_2.npy')\n",
    "#         mode_train3 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_2.npy')\n",
    "#         mode_test = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_test.npy')\n",
    "        \n",
    "#         X_train1, X_train2, X_train3 = mode_train1[:,:-1], mode_train2[:,:-1], mode_train3[:,:-1]\n",
    "#         y_train1, y_train2, y_train3 = mode_train1[:,-1].astype(int).tolist(), mode_train2[:,-1].astype(int).tolist(), mode_train3[:,-1].astype(int).tolist()\n",
    "#         X_test, y_test = mode_test[:,:-1], mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "        \n",
    "#         return X_train1, X_train2, X_train3, y_train1, y_train2, y_train3, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8b014d-0d84-4f78-a8ad-1ff162038f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试用\n",
    "def train_test_dataset(situation, gene_constrain, mode):\n",
    "    if 'gene_balance' in situation:\n",
    "        mode_train = np.load(f'../data/{gene_constrain}/gene_balance/For_ML/{mode}_train.npy', allow_pickle=True)\n",
    "        mode_test = np.load(f'../data/{gene_constrain}/gene_balance/For_ML/{mode}_test.npy', allow_pickle=True)\n",
    "        \n",
    "        X_train = mode_train[:,:-1]\n",
    "        y_train = mode_train[:,-1].astype(int).tolist()\n",
    "        X_test = mode_test[:,:-1]\n",
    "        y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    elif 'gene_not_balance' in situation:\n",
    "        mode_train = np.load(f'../data/{gene_constrain}/gene_not_balance/For_ML/{mode}_train.npy')\n",
    "        mode_test = np.load(f'../data/{gene_constrain}/gene_not_balance/For_ML/{mode}_test.npy')\n",
    "        \n",
    "        X_wt_train = mode_train[:,0:1024]\n",
    "        X_mt_train = mode_train[:,1024:-1]\n",
    "        X_train = X_mt_train - X_wt_train\n",
    "        y_train = mode_train[:,-1].astype(int).tolist()\n",
    "        X_wt_test = mode_test[:,0:1024]\n",
    "        X_mt_test = mode_test[:,1024:-1]\n",
    "        X_test = X_mt_test - X_wt_test\n",
    "        y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    elif 'imbalance' in situation:\n",
    "        mode_train = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train.npy')\n",
    "        mode_test = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_test.npy')\n",
    "\n",
    "        X_train = mode_train[:,:-1]\n",
    "        y_train = mode_train[:,-1].astype(int).tolist()\n",
    "        X_test = mode_test[:,:-1]\n",
    "        y_test = mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    else:\n",
    "        mode_train1 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_1.npy')\n",
    "        mode_train2 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_2.npy')\n",
    "        mode_train3 = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_train_2.npy')\n",
    "        mode_test = np.load(f'../data/{gene_constrain}/{situation}/For_ML/{mode}_test.npy')\n",
    "        \n",
    "        X_train1, X_train2, X_train3 = mode_train1[:,:-1], mode_train2[:,:-1], mode_train3[:,:-1]\n",
    "        y_train1, y_train2, y_train3 = mode_train1[:,-1].astype(int).tolist(), mode_train2[:,-1].astype(int).tolist(), mode_train3[:,-1].astype(int).tolist()\n",
    "        X_test, y_test = mode_test[:,:-1], mode_test[:,-1].astype(int).tolist()\n",
    "        \n",
    "        \n",
    "        return X_train1, X_train2, X_train3, y_train1, y_train2, y_train3, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e3f876-3b5d-4f4e-b3bc-5ddf6a8497f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: MPS\n"
     ]
    }
   ],
   "source": [
    "#使用GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "elif torch.has_mps:\n",
    "    torch.cuda.manual_seed(2022)\n",
    "    device = torch.device('mps')\n",
    "    print('Device name: MPS')\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d493ba8-d1fd-4d46-8375-ec8b8fdc3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dcd6fbc-a686-4ece-8096-e1404302b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_list = ['encoder.block.23','final_layer_norm']\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'encoder.block.23' in name:\n",
    "#         print(name,param.requires_grad)\n",
    "#     elif 'final_layer_norm' in name:\n",
    "#         print(name, param.requires_grad)\n",
    "#     # if 'encoder.block.23' in name:\n",
    "#     #     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2939854f-2002-443d-81cf-3127e93198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     # if 'encoder.block.23' in name:\n",
    "#         print(name, param.requires_grad)\n",
    "#         # print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5ad68-270a-44ca-bff5-96ff7acb22ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f429df-5d8f-4ef6-b72b-5d2c8120f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c995660-7e4e-45ca-a9ba-3b635df177d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.encoder.block[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96280d-e54e-4a71-a8ba-369e33e4b750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9411b6-0fa7-479a-9398-3b83caa76f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10913, 10913, 368, 368, 858, 858)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2022\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "gene_constrain = 'gene_constrain'\n",
    "situation = 'gene_not_balance'\n",
    "mode = 'mode2'\n",
    "\n",
    "# data_X, data_y= data_for_downstream('../data/imbalance_same_seq/Embedding_results_csv/mode_2_embeds')\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_dataset(situation, gene_constrain,mode)\n",
    "\n",
    "# 切分数据集\n",
    "# X_train, X_test, y_train, y_test= train_test_split(data_X, data_y,\n",
    "#                                                     test_size=0.2,\n",
    "#                                                     stratify=data_y,\n",
    "#                                                    random_state=SEED)\n",
    "# 切分出valid数据集\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test,\n",
    "                                               test_size=0.3,\n",
    "                                               shuffle=True,\n",
    "                                               stratify=y_test,\n",
    "                                               random_state=SEED)\n",
    "\n",
    "len(X_train), len(y_train),len(X_test),len(y_test),len(X_valid), len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fc7690-6864-4394-8652-df6f766fcf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9814ea-71b7-440a-aac0-4cd114806fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4428303390741348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64509559-d59e-4a06-bd44-e7f7e9ef68ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd471d72-a1bc-46d4-bab7-928c68f15c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        X = np.array(X, dtype=np.float16)\n",
    "\n",
    "        self.seq = torch.tensor(X)\n",
    "        self.seq = self.seq.to(torch.float32)\n",
    "        self.label = torch.tensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.seq[index], self.label[index]\n",
    "\n",
    "batch_size = 3\n",
    "accumulation_step = 2\n",
    "\n",
    "train_dataset = TestDataset(X_train, y_train)\n",
    "test_dataset = TestDataset(X_test, y_test)\n",
    "val_dataset = TestDataset(X_valid, y_valid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0361861-c5c4-46d0-845a-c5459c36217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0164, -0.0124, -0.0073,  ..., -0.0098, -0.0099,  0.0568],\n",
      "        [ 0.0095, -0.0090, -0.0118,  ..., -0.0101,  0.0257,  0.0007],\n",
      "        [-0.0142, -0.0640,  0.0014,  ..., -0.0370, -0.0154,  0.0340]])\n",
      "tensor([1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0])\n",
    "    print(batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce7d61-95cc-4947-a4fa-4af6d14153ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5238dd4c-c2ec-4c5c-b4fd-5d44b20cdb1f",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5bd932-7bf8-480f-97ba-dca222d38c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create the MLPClassfier class\n",
    "class MLPClassifier(nn.Module):\n",
    "    \"\"\"Simple MLP Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self,num_input,num_hidden,num_output):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.hidden=nn.Linear(num_input,num_hidden)\n",
    "        # self.dropout=nn.Dropout(0.1,inplace= False)\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            # nn.Linear(num_hidden, num_output)\n",
    "            nn.Linear(num_hidden, 768),\n",
    "            nn.Dropout(0.1),\n",
    "            # # nn.ReLU(inplace = True),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.1),\n",
    "            # # nn.ReLU(),\n",
    "            # nn.Linear(256, 64),\n",
    "            nn.Linear(256, num_output)\n",
    "        )\n",
    "           \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        # x = self.dropout(x)\n",
    "        x=self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ad0097-3f61-402e-bfeb-b94f9076da97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP_Attention_Classifier(nn.Module):\n",
    "    \"\"\"Simple MLP Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self,num_input,num_hidden,num_output):\n",
    "        super(MLP_Attention_Classifier, self).__init__()\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.hidden=nn.Linear(num_input,num_hidden)\n",
    "        # self.dropout=nn.Dropout(0.1,inplace= False)\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            # nn.Linear(num_hidden, 2)\n",
    "            nn.Linear(num_hidden, 768),\n",
    "            nn.Dropout(0.1),\n",
    "            # # nn.ReLU(inplace = True),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.1),\n",
    "            # # nn.ReLU(),\n",
    "            # nn.Linear(256, 64),\n",
    "            nn.Linear(256, num_output)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(256, eps=1e-6)\n",
    "           \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.layer_norm(x)\n",
    "        # x = self.dropout(x)\n",
    "        x=self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55da1254-6514-47f3-b837-4313abe947e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "if gene_constrain == 'ohe_constrain':\n",
    "    input_size = 2088\n",
    "\n",
    "elif gene_constrain == 'gene_constrain':\n",
    "    input_size = 1024\n",
    "else:\n",
    "    print('constrain_error')\n",
    "print(input_size)\n",
    "    \n",
    "model = MLPClassifier(num_input = input_size, num_hidden = 832, num_output = 2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8815724-c65f-46be-8396-64d16431f197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c674878-73bd-429d-a374-f7da5fd15d27",
   "metadata": {},
   "source": [
    "## 定义训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d22874e7-9afa-4c5c-8c02-add0921dddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mweininglin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/acetylcoa/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Coding/for_server/T5_Protein_Sequence/ipynb_files/wandb/run-20221001_185212-zgtvc76s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/weininglin/pytorch-intro/runs/zgtvc76s\" target=\"_blank\">silver-shape-98</a></strong> to <a href=\"https://wandb.ai/weininglin/pytorch-intro\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/weininglin/pytorch-intro/runs/zgtvc76s?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2c4e8c8e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "# 精度计算\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = preds.detach().cpu().numpy()\n",
    "    pred_flat = np.argmax(pred_flat, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "# 优化方法\n",
    "n_epochs = 20\n",
    "early_stop = 8\n",
    "learning_rate = 1e-4\n",
    "total_steps = len(train_loader) * 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(train_loader)*n_epochs)\n",
    "\n",
    "\n",
    "# wandb\n",
    "wandb.init(\n",
    "        project=\"pytorch-intro\",\n",
    "        config={\n",
    "            \"epochs\": n_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": learning_rate,\n",
    "            \"dropout\": 0.1,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a5070a9-2bbe-4cd2-896c-483c5d9db0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, val_loader, model=model, device = device, early_stop = early_stop, n_epochs = n_epochs, accumulation_step = accumulation_step):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() # Define your loss function, do not modify this.\n",
    "\n",
    "    # Define your optimization algorithm. \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.0000) \n",
    "    writer = SummaryWriter() # Writer of tensoboard.\n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = n_epochs, math.inf, 0, early_stop\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for batch in train_pbar:\n",
    "           \n",
    "            b_seq, b_labels = tuple(t.to(device) for t in batch) # Move your data to device. \n",
    "            # print('b_seq shape: ', b_seq.shape)\n",
    "            pred = model(b_seq)  \n",
    "            loss = criterion(pred, b_labels)\n",
    "            \n",
    "            loss = loss/step\n",
    "            \n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            \n",
    "            if ((i+1)% accumulation_steps ==0):\n",
    "                \n",
    "                optimizer.step()                    # Update parameters.\n",
    "                # scheduler.step()\n",
    "                optimizer.zero_grad()               # Set gradient to zero.\n",
    "\n",
    "            step += 1\n",
    "                \n",
    "            loss_record.append(loss.detach().item())\n",
    "            \n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "            \n",
    "            wandb.log({'epoch': n_epochs, 'loss': loss.detach().item(), 'step': step})\n",
    "            # print(model.classifier[3].bias)\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "        wandb.log({'epoch': n_epochs, 'mean_train_loss': mean_train_loss, 'epoch_step': step})\n",
    "\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        total_eval_accuracy = 0\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            \n",
    "            b_seq, b_labels = tuple(t.to(device) for t in batch) # Move your data to device. \n",
    "            # pred = model(b_input_ids, b_attn_mask) \n",
    "            with torch.no_grad():\n",
    "                pred = model(b_seq)\n",
    "                loss = criterion(pred, b_labels)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "            total_eval_accuracy += flat_accuracy(pred, b_labels)\n",
    "            \n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "        wandb.log({'epoch': n_epochs,\n",
    "            'val_loss': mean_valid_loss,\n",
    "            'step': step,\n",
    "            'accuracy': avg_val_accuracy}\n",
    "                 )\n",
    "        \n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), './models/model.ckpt') # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            \n",
    "            \n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08911e2c-f4b4-4318-9afa-0277bb21a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: 100%|██████████████| 683/683 [00:13<00:00, 49.56it/s, loss=0.0347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: Train loss: 0.4744, Valid loss: 0.4139\n",
      "Saving model with loss 0.414...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|████████████████| 683/683 [00:13<00:00, 51.54it/s, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: Train loss: 0.4337, Valid loss: 0.4118\n",
      "Saving model with loss 0.412...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: 100%|███████████████| 683/683 [00:13<00:00, 50.43it/s, loss=0.199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: Train loss: 0.4218, Valid loss: 0.4107\n",
      "Saving model with loss 0.411...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: 100%|███████████████| 683/683 [00:13<00:00, 51.27it/s, loss=0.651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: Train loss: 0.4097, Valid loss: 0.4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: 100%|███████████████| 683/683 [00:13<00:00, 50.31it/s, loss=0.593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: Train loss: 0.3986, Valid loss: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: 100%|███████████████| 683/683 [00:13<00:00, 50.70it/s, loss=0.663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: Train loss: 0.3860, Valid loss: 0.4064\n",
      "Saving model with loss 0.406...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: 100%|██████████████| 683/683 [00:13<00:00, 50.89it/s, loss=0.0337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: Train loss: 0.3700, Valid loss: 0.3979\n",
      "Saving model with loss 0.398...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: 100%|██████████████| 683/683 [00:13<00:00, 50.67it/s, loss=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: Train loss: 0.3651, Valid loss: 0.4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: 100%|██████████████| 683/683 [00:13<00:00, 51.30it/s, loss=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: Train loss: 0.3547, Valid loss: 0.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: 100%|███████████████| 683/683 [00:13<00:00, 50.40it/s, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: Train loss: 0.3491, Valid loss: 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: 100%|█████████████| 683/683 [00:13<00:00, 50.98it/s, loss=0.0424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: Train loss: 0.3386, Valid loss: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: 100%|█████████████| 683/683 [00:13<00:00, 50.59it/s, loss=0.0101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: Train loss: 0.3312, Valid loss: 0.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: 100%|██████████████| 683/683 [00:13<00:00, 50.20it/s, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: Train loss: 0.3199, Valid loss: 0.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: 100%|███████████████| 683/683 [00:13<00:00, 50.85it/s, loss=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: Train loss: 0.3170, Valid loss: 0.4293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]: 100%|████████████████| 683/683 [00:13<00:00, 50.98it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]: Train loss: 0.3059, Valid loss: 0.4722\n",
      "\n",
      "Model is not improving, so we halt the training session.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>▆▂▃▃▅▇▃▅▄▆█▃▁▆▃▄▄▆▇▆▄▅▃▆▁▂▂▁▃▃▂▃▅▃▅▁▂▂▁▅</td></tr><tr><td>mean_train_loss</td><td>█▆▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▃▂▂▃▃▂▁▃▅▅▅▃▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.0</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_step</td><td>10245</td></tr><tr><td>loss</td><td>1.50043</td></tr><tr><td>mean_train_loss</td><td>0.30586</td></tr><tr><td>step</td><td>10245</td></tr><tr><td>val_loss</td><td>0.47224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">efficient-music-92</strong>: <a href=\"https://wandb.ai/weininglin/pytorch-intro/runs/2mf1fcn4\" target=\"_blank\">https://wandb.ai/weininglin/pytorch-intro/runs/2mf1fcn4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220921_201857-2mf1fcn4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer(train_loader, val_loader, model, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ffed7-6f0a-4928-905a-71bac18dc346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7112d17-f71c-472d-b395-007daabff1e7",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aafe3da-c2ec-48d6-8ea6-91e6bc8001ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        b_seq, b_labels = tuple(t.to(device) for t in batch)                   \n",
    "        with torch.no_grad():                   \n",
    "            pred = model(b_seq)                     \n",
    "            preds.append(pred.detach().cpu()) # 放入cpu计算\n",
    "            labels.append(b_labels.detach().cpu())\n",
    "            \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    # print(preds)\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "\n",
    "    return preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77bd0331-7bbf-4d2c-bdcb-8f9920130f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 201.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9131, -1.0042],\n",
      "        [ 0.8193, -1.0125],\n",
      "        [ 0.2308, -0.2367],\n",
      "        [ 0.9075, -0.9684],\n",
      "        [ 0.2734, -0.3054],\n",
      "        [-1.5017,  1.6380],\n",
      "        [-0.7443,  0.9126],\n",
      "        [ 0.3497, -0.5148],\n",
      "        [ 0.6169, -0.6524],\n",
      "        [-0.0206,  0.1513],\n",
      "        [-1.8187,  1.9764],\n",
      "        [ 0.7252, -0.7710],\n",
      "        [ 0.2287, -0.2368],\n",
      "        [ 0.7413, -0.7891],\n",
      "        [-1.8705,  2.1593],\n",
      "        [ 2.4098, -2.5315],\n",
      "        [-1.3849,  1.6613],\n",
      "        [ 0.5396, -0.5688],\n",
      "        [-1.1419,  1.2752],\n",
      "        [ 0.6522, -0.6855],\n",
      "        [ 1.0768, -1.1228],\n",
      "        [-0.4351,  0.4865],\n",
      "        [ 0.9461, -1.0016],\n",
      "        [ 2.5369, -2.6882],\n",
      "        [-1.7552,  1.9441],\n",
      "        [ 0.7266, -0.7618],\n",
      "        [ 0.6463, -0.6919],\n",
      "        [ 0.7189, -0.7581],\n",
      "        [ 0.5671, -0.5946],\n",
      "        [ 1.0248, -1.0970],\n",
      "        [ 0.5596, -0.5998],\n",
      "        [ 0.0620, -0.0268],\n",
      "        [-1.0331,  1.2105],\n",
      "        [ 0.8712, -0.9129],\n",
      "        [ 0.1978, -0.2020],\n",
      "        [ 1.7609, -1.8594],\n",
      "        [ 0.4867, -0.5188],\n",
      "        [ 1.8599, -1.9423],\n",
      "        [ 0.7175, -0.7739],\n",
      "        [-0.3524,  0.4560],\n",
      "        [ 0.4976, -0.5244],\n",
      "        [ 1.4834, -1.5821],\n",
      "        [ 0.5727, -0.6021],\n",
      "        [ 0.3992, -0.4707],\n",
      "        [ 0.8728, -0.9129],\n",
      "        [ 2.5039, -2.6669],\n",
      "        [ 0.8431, -0.9100],\n",
      "        [ 0.7548, -0.6324],\n",
      "        [ 0.4232, -0.4410],\n",
      "        [ 0.9019, -0.9600],\n",
      "        [ 0.6967, -0.7315],\n",
      "        [-0.1563,  0.2329],\n",
      "        [ 0.4664, -0.4708],\n",
      "        [ 3.0144, -3.0420],\n",
      "        [-0.5950,  0.6483],\n",
      "        [ 0.4829, -0.5256],\n",
      "        [-1.2750,  1.4584],\n",
      "        [-0.0677,  0.0944],\n",
      "        [-1.8135,  1.9833],\n",
      "        [ 1.0647, -1.1273],\n",
      "        [-0.5308,  0.5856],\n",
      "        [ 0.9407, -0.9969],\n",
      "        [ 1.1798, -1.2929],\n",
      "        [ 1.0307, -1.0893],\n",
      "        [ 0.5776, -0.6107],\n",
      "        [ 0.4937, -0.5238],\n",
      "        [ 0.4743, -0.5196],\n",
      "        [-0.7728,  0.8527],\n",
      "        [ 1.3292, -1.3952],\n",
      "        [ 0.7689, -0.8338],\n",
      "        [-0.7777,  0.8604],\n",
      "        [-0.1809,  0.2108],\n",
      "        [ 0.0557, -0.0486],\n",
      "        [ 1.1131, -1.1798],\n",
      "        [ 1.4608, -1.5638],\n",
      "        [ 0.6040, -0.6505],\n",
      "        [ 0.5066, -0.5358],\n",
      "        [-0.3924,  0.4559],\n",
      "        [ 2.2082, -2.3209],\n",
      "        [ 0.7957, -0.8418],\n",
      "        [ 0.6600, -0.7503],\n",
      "        [-1.1515,  1.3494],\n",
      "        [ 0.5225, -0.5496],\n",
      "        [-1.4921,  1.7470],\n",
      "        [ 0.7495, -0.7849],\n",
      "        [ 0.8599, -0.9285],\n",
      "        [ 2.3045, -2.4577],\n",
      "        [-0.0390,  0.0763],\n",
      "        [ 0.5438, -0.5698],\n",
      "        [ 0.7293, -0.7664],\n",
      "        [ 2.5678, -2.7443],\n",
      "        [ 0.6235, -0.6485],\n",
      "        [ 1.3312, -1.4813],\n",
      "        [ 1.3496, -1.4267],\n",
      "        [ 1.0188, -1.0857],\n",
      "        [ 1.1091, -1.1820],\n",
      "        [-0.9609,  1.0433],\n",
      "        [ 1.9615, -2.0491],\n",
      "        [ 0.9878, -1.0478],\n",
      "        [ 0.9504, -1.0093],\n",
      "        [ 2.5771, -2.6903],\n",
      "        [ 0.1435, -0.3271],\n",
      "        [ 0.7613, -0.9722],\n",
      "        [ 3.8476, -3.8108],\n",
      "        [ 1.2091, -1.2760],\n",
      "        [ 0.7562, -0.8315],\n",
      "        [ 0.2899, -0.3305],\n",
      "        [ 3.7713, -3.7456],\n",
      "        [ 1.4359, -1.5022],\n",
      "        [ 1.1219, -1.1921],\n",
      "        [ 1.1672, -1.2477],\n",
      "        [ 0.8245, -0.8702],\n",
      "        [ 0.2133, -0.2135],\n",
      "        [ 0.8690, -0.9125],\n",
      "        [ 0.7808, -0.8373],\n",
      "        [-1.2890,  1.5107],\n",
      "        [ 1.2795, -1.3803],\n",
      "        [ 0.8569, -0.8962],\n",
      "        [ 0.6586, -0.6919],\n",
      "        [ 0.8714, -0.9445],\n",
      "        [ 1.6120, -1.5836],\n",
      "        [ 2.7440, -2.7300],\n",
      "        [-1.7100,  1.9465],\n",
      "        [ 3.3980, -3.6048],\n",
      "        [ 2.4447, -2.6237],\n",
      "        [-1.9308,  2.1578],\n",
      "        [ 1.3441, -1.4738],\n",
      "        [ 2.4776, -2.6017],\n",
      "        [ 2.5993, -2.7523],\n",
      "        [-1.4578,  1.6108],\n",
      "        [ 0.5511, -0.6064],\n",
      "        [ 0.5339, -0.5659],\n",
      "        [ 0.8136, -0.8753],\n",
      "        [ 0.5265, -0.5563],\n",
      "        [-0.6402,  0.7004],\n",
      "        [ 0.8543, -0.8725],\n",
      "        [ 1.1130, -1.2008],\n",
      "        [ 0.5355, -0.5676],\n",
      "        [-0.2407,  0.2960],\n",
      "        [ 0.6237, -0.6650],\n",
      "        [ 0.3962, -0.4193],\n",
      "        [ 0.6916, -0.8034],\n",
      "        [ 0.8963, -0.8982],\n",
      "        [ 0.8060, -0.8565],\n",
      "        [ 0.8649, -0.9159],\n",
      "        [ 0.8543, -0.9738],\n",
      "        [ 1.0758, -1.1291],\n",
      "        [-0.4807,  0.5755],\n",
      "        [-2.0788,  2.3261],\n",
      "        [ 0.9015, -0.9704],\n",
      "        [-0.3025,  0.4054],\n",
      "        [ 1.7646, -2.0178],\n",
      "        [-0.4324,  0.4814],\n",
      "        [-1.0908,  1.1841],\n",
      "        [ 0.8275, -0.8464],\n",
      "        [ 0.3702, -0.3266],\n",
      "        [ 1.8038, -1.8376],\n",
      "        [ 0.9512, -1.0186],\n",
      "        [ 2.5227, -2.6379],\n",
      "        [ 1.0865, -1.1271],\n",
      "        [-1.8115,  2.0200],\n",
      "        [ 1.9678, -2.0772],\n",
      "        [ 1.1006, -1.1683],\n",
      "        [ 0.8899, -0.9700],\n",
      "        [ 0.2774, -0.3343],\n",
      "        [ 1.1241, -1.1788],\n",
      "        [ 2.7738, -2.8953],\n",
      "        [ 0.6096, -0.6249],\n",
      "        [ 1.8706, -2.0023],\n",
      "        [ 0.6809, -0.7270],\n",
      "        [ 0.7987, -0.8437],\n",
      "        [ 0.6172, -0.6085],\n",
      "        [ 0.7811, -0.8301],\n",
      "        [ 1.0669, -1.1141],\n",
      "        [-1.5215,  1.6902],\n",
      "        [ 0.5712, -0.5906],\n",
      "        [ 1.0009, -1.0534],\n",
      "        [ 2.1768, -2.3285],\n",
      "        [ 0.1849, -0.2929],\n",
      "        [ 0.4829, -0.5389],\n",
      "        [ 0.6002, -0.6147],\n",
      "        [ 0.3679, -0.4123],\n",
      "        [-1.1295,  1.2669],\n",
      "        [ 0.6690, -0.6900],\n",
      "        [ 0.4344, -0.4635],\n",
      "        [ 0.9143, -0.9610],\n",
      "        [ 0.7296, -0.7787],\n",
      "        [ 1.1331, -1.1987],\n",
      "        [-2.2660,  2.5596],\n",
      "        [ 0.4628, -0.4888],\n",
      "        [ 0.6458, -0.7295],\n",
      "        [ 1.2582, -1.3066],\n",
      "        [ 1.2866, -1.3481],\n",
      "        [-0.1380,  0.0732],\n",
      "        [ 0.4539, -0.4601],\n",
      "        [ 1.4885, -1.6019],\n",
      "        [ 0.5166, -0.5416],\n",
      "        [-1.1053,  1.2288],\n",
      "        [ 0.0842, -0.0839],\n",
      "        [ 3.2689, -3.4512],\n",
      "        [-1.5107,  1.6820],\n",
      "        [ 1.0556, -1.1115],\n",
      "        [ 1.1948, -1.2763],\n",
      "        [-0.2266,  0.2494],\n",
      "        [ 2.7847, -2.9519],\n",
      "        [ 1.0656, -1.0666],\n",
      "        [ 0.8214, -0.8636],\n",
      "        [ 0.6922, -0.7243],\n",
      "        [ 0.9984, -1.0620],\n",
      "        [-0.6085,  0.6683],\n",
      "        [ 1.2882, -1.3603],\n",
      "        [ 0.8062, -0.8471],\n",
      "        [-0.8208,  0.9572],\n",
      "        [-1.0308,  1.1891],\n",
      "        [ 1.6144, -1.7517],\n",
      "        [ 0.8949, -0.9413],\n",
      "        [ 1.4323, -1.5031],\n",
      "        [-0.8212,  0.9933],\n",
      "        [-0.1023,  0.0281],\n",
      "        [ 0.0377, -0.0236],\n",
      "        [-0.5105,  0.5513],\n",
      "        [ 0.9424, -1.0436],\n",
      "        [ 1.3150, -1.3933],\n",
      "        [ 0.3099, -0.0979],\n",
      "        [ 1.1133, -1.1790],\n",
      "        [ 0.3442, -0.3069],\n",
      "        [ 1.0134, -1.1428],\n",
      "        [ 1.1336, -1.1748],\n",
      "        [ 0.0914, -0.0737],\n",
      "        [-0.3875,  0.1905],\n",
      "        [-1.0496,  1.1783],\n",
      "        [ 2.0077, -2.1472],\n",
      "        [ 0.9886, -1.0637],\n",
      "        [ 0.2855, -0.2241],\n",
      "        [-0.1760,  0.2026],\n",
      "        [ 0.5561, -0.5702],\n",
      "        [ 1.2478, -1.2809],\n",
      "        [ 0.0306,  0.0366],\n",
      "        [ 0.5062, -0.5332],\n",
      "        [ 0.8049, -0.8883],\n",
      "        [ 0.4743, -0.5296],\n",
      "        [ 1.0360, -1.0553],\n",
      "        [ 0.5522, -0.5353],\n",
      "        [ 0.6294, -0.6799],\n",
      "        [ 0.7834, -0.8327],\n",
      "        [ 0.1182, -0.1886],\n",
      "        [ 0.8288, -0.8389],\n",
      "        [ 0.9668, -1.0267],\n",
      "        [ 0.1330, -0.1183],\n",
      "        [-0.2437,  0.2907],\n",
      "        [ 1.0186, -1.0973],\n",
      "        [ 0.8574, -0.9157],\n",
      "        [ 0.6159, -0.6944],\n",
      "        [ 2.2065, -2.3415],\n",
      "        [ 2.4586, -2.5923],\n",
      "        [ 0.5869, -0.6250],\n",
      "        [ 3.4893, -3.6352],\n",
      "        [ 2.3829, -2.5405],\n",
      "        [ 0.9701, -0.9999],\n",
      "        [ 0.5902, -0.6471],\n",
      "        [ 0.9115, -0.9921],\n",
      "        [ 0.8959, -0.9543],\n",
      "        [ 0.2910, -0.3189],\n",
      "        [ 1.1897, -1.3044],\n",
      "        [ 1.4164, -1.4957],\n",
      "        [ 1.9991, -2.0125],\n",
      "        [ 1.1034, -1.1793],\n",
      "        [-1.8466,  2.0240],\n",
      "        [ 0.9194, -0.9999],\n",
      "        [-1.7091,  1.8772],\n",
      "        [-0.3185,  0.3535],\n",
      "        [ 1.5653, -1.6570],\n",
      "        [ 0.7016, -0.7293],\n",
      "        [ 0.5400, -0.5686],\n",
      "        [ 0.9104, -0.9790],\n",
      "        [ 2.0965, -2.2303],\n",
      "        [ 0.0295, -0.0243],\n",
      "        [-1.5923,  1.7975],\n",
      "        [ 0.9192, -0.9637],\n",
      "        [ 3.7447, -3.9383],\n",
      "        [ 0.5006, -0.4593],\n",
      "        [ 0.9729, -1.0835],\n",
      "        [ 1.0893, -1.1505],\n",
      "        [-0.7351,  0.8445],\n",
      "        [ 0.6942, -0.7227],\n",
      "        [ 0.2631, -0.2779],\n",
      "        [ 0.3424, -0.3502],\n",
      "        [ 1.0034, -1.0613],\n",
      "        [ 0.7197, -0.7488],\n",
      "        [-0.2232,  0.2489],\n",
      "        [ 1.1044, -1.2865],\n",
      "        [-1.1536,  1.3322],\n",
      "        [ 2.6806, -2.8153],\n",
      "        [ 1.2678, -1.3546],\n",
      "        [ 0.8398, -0.9029],\n",
      "        [ 1.1663, -1.2626],\n",
      "        [ 0.7957, -0.8539],\n",
      "        [ 0.7780, -0.8332],\n",
      "        [-0.1670,  0.0792],\n",
      "        [ 0.9113, -0.9601],\n",
      "        [-0.7052,  0.7757],\n",
      "        [ 0.6438, -0.7032],\n",
      "        [ 0.8960, -0.9386],\n",
      "        [-1.5021,  1.7216],\n",
      "        [-2.4697,  2.7866],\n",
      "        [ 0.2145, -0.1746],\n",
      "        [-0.4386,  0.4770],\n",
      "        [ 0.1202, -0.1159],\n",
      "        [ 0.8622, -0.9174],\n",
      "        [ 0.4489, -0.4691],\n",
      "        [ 1.1298, -1.1884],\n",
      "        [ 0.6220, -0.6763],\n",
      "        [-2.0157,  2.1840],\n",
      "        [ 2.9228, -3.0847],\n",
      "        [ 0.9494, -1.0282],\n",
      "        [-1.5353,  1.6853],\n",
      "        [ 0.5439, -0.5818],\n",
      "        [-0.5926,  0.7388],\n",
      "        [ 0.1252, -0.1236],\n",
      "        [ 1.2882, -1.3512],\n",
      "        [-2.3284,  2.6137],\n",
      "        [ 1.0270, -1.0970],\n",
      "        [ 0.9973, -1.1158],\n",
      "        [-1.0357,  1.1553],\n",
      "        [ 0.3910, -0.4073],\n",
      "        [-0.1944,  0.2154],\n",
      "        [ 1.3272, -1.4119],\n",
      "        [ 0.7866, -0.8283],\n",
      "        [-0.8818,  0.9860],\n",
      "        [ 0.8578, -0.9131],\n",
      "        [ 0.9338, -0.9775],\n",
      "        [ 0.6758, -0.7115],\n",
      "        [ 1.0863, -1.1593],\n",
      "        [ 0.4862, -0.5335],\n",
      "        [-1.2471,  1.3699],\n",
      "        [ 0.7453, -0.7983],\n",
      "        [ 0.9611, -1.0137],\n",
      "        [ 0.8213, -0.8635],\n",
      "        [ 1.0950, -1.0930],\n",
      "        [ 1.9535, -2.0339],\n",
      "        [ 0.7409, -0.8414],\n",
      "        [ 0.2358, -0.2424],\n",
      "        [ 0.1245, -0.0783],\n",
      "        [ 0.8091, -0.7646],\n",
      "        [ 0.9259, -0.9700],\n",
      "        [-1.7763,  1.9789],\n",
      "        [ 0.7257, -0.7944],\n",
      "        [ 0.7232, -0.7365],\n",
      "        [ 2.5199, -2.6857],\n",
      "        [ 1.1447, -1.1362],\n",
      "        [ 0.4184, -0.4308],\n",
      "        [-1.1643,  1.3302],\n",
      "        [ 0.1948, -0.1829],\n",
      "        [ 1.5720, -1.7189],\n",
      "        [ 1.8187, -1.9182],\n",
      "        [-0.2341,  0.2746],\n",
      "        [ 1.3696, -1.4445],\n",
      "        [-0.6078,  0.7283],\n",
      "        [ 0.9803, -1.1105],\n",
      "        [-1.2024,  1.3427],\n",
      "        [ 0.0144, -0.0058],\n",
      "        [ 0.8932, -0.9410],\n",
      "        [ 0.8866, -0.9606],\n",
      "        [-0.0095,  0.0445],\n",
      "        [-0.4081,  0.4465],\n",
      "        [ 2.3368, -2.4904],\n",
      "        [ 0.7042, -0.6688],\n",
      "        [ 0.8861, -0.9408]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model =  MLPClassifier(num_input = input_size, num_hidden = 832, num_output = 2).to(device)\n",
    "model.load_state_dict(torch.load('./models/model.ckpt'))\n",
    "preds, y_true = predict(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f32f2b2-e394-4650-adf0-74fbf51e044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       268\n",
      "           1       0.73      0.60      0.66       100\n",
      "\n",
      "    accuracy                           0.83       368\n",
      "   macro avg       0.80      0.76      0.77       368\n",
      "weighted avg       0.83      0.83      0.83       368\n",
      "\n",
      "{'precision': 0.8252397125673901, 'recall': 0.8315217391304348, 'f1-score': 0.8259274080181317, 'support': 368}\n",
      "MCC:  0.5536459487403476\n"
     ]
    }
   ],
   "source": [
    "label_names = {'0':0, '1':1}\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "report = classification_report(y_true, preds,target_names=label_names)\n",
    "report_df = classification_report(y_true, preds,target_names=label_names, output_dict=True)\n",
    "print(report)\n",
    "\n",
    "print(report_df['weighted avg'])\n",
    "MCC = matthews_corrcoef(y_true, preds)\n",
    "print('MCC: ', MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bbfd5a9-8b6a-4f03-a092-2c4b382dc707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True Positive  True Negative  False Positive  False Negative\n",
      "0             60            246              22              40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "print(pd.DataFrame([{'True Positive':tp,'True Negative':tn,'False Positive':fp,'False Negative':fn}]))\n",
    "# print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dca26b-9f78-4362-ae41-25bb0de4078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '../data' + '/' + gene_constrain + '/' + situation + '/' + f'ML_predicted_results/{mode}_results'\n",
    "report_csv = pd.DataFrame(report_df).transpose()\n",
    "report_csv['MCC'] = MCC\n",
    "report_csv['True Positive'] = tp\n",
    "report_csv['True Negative'] = tn\n",
    "report_csv['False Positive'] = fp\n",
    "report_csv['False Negative'] = fn\n",
    "\n",
    "report_csv.to_csv(f'{result_path}/mlp_{mode}_report_save.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77c446-3b63-4955-842d-d85416b570ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425864e-4f79-42ef-a85e-1b4f6c5b6c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
