{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2b10b9-4ec0-4dcd-9b05-e4f451edddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import T5Tokenizer, T5Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "from termcolor import colored\n",
    "import dataframe_image as dfi\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn('DelftStack')\n",
    "warnings.warn('Do not show this message')\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "def allDone():\n",
    "    display(Audio(url='https://www.mediacollege.com/downloads/sound-effects/beep/beep-10.wav', autoplay=True))\n",
    "\n",
    "embed_path = '../data/imbalance_same_seq/Embedding_results/model_1_embeds'\n",
    "result_path = 'predicted_results'\n",
    "wt_mt_path = 'data_test/wt_mt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bed2c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2a2f209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1lcmpq8l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2d8069e92e4e93a95591f80eab9bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-voice-5</strong>: <a href=\"https://wandb.ai/weininglin/wandb_on_ucl_server/runs/1lcmpq8l\" target=\"_blank\">https://wandb.ai/weininglin/wandb_on_ucl_server/runs/1lcmpq8l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220917_182438-1lcmpq8l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1lcmpq8l). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/acetylcoa/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Coding/for_server/T5_Protein_Sequence/ipynb_files/wandb/run-20220918_133551-1v5x4obn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/weininglin/wandb_on_ucl_server/runs/1v5x4obn\" target=\"_blank\">sleek-wood-6</a></strong> to <a href=\"https://wandb.ai/weininglin/wandb_on_ucl_server\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/weininglin/wandb_on_ucl_server/runs/1v5x4obn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x424756f70>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='wandb_on_ucl_server')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4d57-30e3-4852-92da-0d911935943a",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67986c7f-6337-4429-8e7a-fde343360e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq = pd.read_csv('../data/mode1_for_embed.csv')\n",
    "# add space between each amino aicds\n",
    "protein_seq['wt_seq'] = protein_seq['wt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))\n",
    "protein_seq['mt_seq'] = protein_seq['mt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c1eb6-ee47-4c88-a68d-9ff1ec83932c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f941853-6486-47f6-ab81-da1812561920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "27745    0\n",
       "27746    0\n",
       "27747    1\n",
       "27748    1\n",
       "27749    1\n",
       "Name: label, Length: 27750, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2377f2d-1779-4784-bdf6-85b514015c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20655\n",
       "1     7095\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9d7400-59bc-4140-86e9-3bf6ac12a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = set(protein_seq['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4cb4a6-2808-45a1-8969-9c17ebfa7e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb1316-78b6-4433-ac5d-d8781ecf8aaf",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d20d7f-78b0-431b-b49b-98a4e08e8e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: MPS\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "# max_seq_len = 380\n",
    "batch_size = 16\n",
    "SEED = 2022\n",
    "\n",
    "embed_path = '../data'\n",
    "result_path = './predicted_results'\n",
    "\n",
    "#使用GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "elif torch.has_mps:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    device = torch.device('mps')\n",
    "    print('Device name: MPS')\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01a6c38-650f-4f67-85e8-09fa06b6c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b613fd9-c07a-428d-a66a-09f0fb4a8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(name)\n",
    "# print(model.encoder.block[23], model.encoder.final_layer_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7493989c-cdf9-4579-b199-a1760229b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e2d310b-2563-472b-bf55-6dbcac477242",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_test = protein_seq[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b88f0f82-b5fa-4592-a14c-5b2957a09726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>aa_index</th>\n",
       "      <th>Length</th>\n",
       "      <th>wt</th>\n",
       "      <th>mt</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NP_689699.2</td>\n",
       "      <td>56</td>\n",
       "      <td>681</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NP_689699.2</td>\n",
       "      <td>665</td>\n",
       "      <td>681</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NP_056473.3</td>\n",
       "      <td>203</td>\n",
       "      <td>749</td>\n",
       "      <td>A</td>\n",
       "      <td>V</td>\n",
       "      <td>M A A A G S R K R R L A E L T V D E F L A S G ...</td>\n",
       "      <td>M A A A G S R K R R L A E L T V D E F L A S G ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NP_001354481.1</td>\n",
       "      <td>358</td>\n",
       "      <td>623</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         gene_id  aa_index  Length wt mt  \\\n",
       "0           0     NP_689699.2        56     681  G  S   \n",
       "1           1     NP_689699.2       665     681  G  A   \n",
       "2           2     NP_056473.3       203     749  A  V   \n",
       "3           6  NP_001354481.1       358     623  G  D   \n",
       "\n",
       "                                              wt_seq  \\\n",
       "0  M S K G I L Q V H P P I C D C P G C R I S S P ...   \n",
       "1  M S K G I L Q V H P P I C D C P G C R I S S P ...   \n",
       "2  M A A A G S R K R R L A E L T V D E F L A S G ...   \n",
       "3  M G N S H C V P Q A P R R L R A S F S R K P S ...   \n",
       "\n",
       "                                              mt_seq  label  \n",
       "0  M S K G I L Q V H P P I C D C P G C R I S S P ...      0  \n",
       "1  M S K G I L Q V H P P I C D C P G C R I S S P ...      0  \n",
       "2  M A A A G S R K R R L A E L T V D E F L A S G ...      0  \n",
       "3  M G N S H C V P Q A P R R L R A S F S R K P S ...      0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ba16f0d-c316-4d8a-9d53-981e25c3b28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "wt_emb:  torch.Size([1, 682, 1024])\n",
      "wt_aa shape:  torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████▎                                 | 1/4 [00:01<00:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "wt_emb:  torch.Size([1, 682, 1024])\n",
      "wt_aa shape:  torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "wt_emb:  torch.Size([1, 750, 1024])\n",
      "wt_aa shape:  torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "wt_emb:  torch.Size([1, 624, 1024])\n",
      "wt_aa shape:  torch.Size([1, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# soft gate\n",
    "\n",
    "# tokenizer = config.tokenizer\n",
    "# model = config.model\n",
    "\n",
    "aa_emb = []\n",
    "seq_emb = []\n",
    "result = None\n",
    "count = 0\n",
    "embed_error_count = 0\n",
    "# protein_seq = protein_seq[start:stop]\n",
    "data_len = len(protein_test)\n",
    "\n",
    "for index, seq in tqdm(protein_test.iterrows(),total=protein_test.shape[0]):\n",
    "    s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "    aa_index = seq['aa_index']\n",
    "    label = seq['label']\n",
    "    wt_aa = seq['wt']\n",
    "    mt_aa = seq['mt']\n",
    "    wt_seq = seq['wt_seq']\n",
    "    mt_seq = seq['mt_seq']\n",
    "    print(aa_index)\n",
    "    # AF_DB = seq['AlphaFoldDB']\n",
    "    # PDB = seq['PDB']\n",
    "    # pathogenicity = seq['pathogenicity']\n",
    "\n",
    "    # add_special_tokens adds extra token at the end of each sequence\n",
    "    # token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_token_encoding = tokenizer.batch_encode_plus([seq['wt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_input_ids      = torch.tensor(wt_token_encoding['input_ids']).to(device)\n",
    "    # print(wt_input_ids)\n",
    "    wt_attention_mask = torch.tensor(wt_token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    mt_token_encoding = tokenizer.batch_encode_plus([seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    mt_input_ids      = torch.tensor(mt_token_encoding['input_ids']).to(device)\n",
    "    mt_attention_mask = torch.tensor(mt_token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "        wt_embedding_repr =model(wt_input_ids, attention_mask=wt_attention_mask)\n",
    "        wt_emb = wt_embedding_repr.last_hidden_state[:, :s_len]\n",
    "        print('wt_emb: ', wt_emb.shape)\n",
    "        wt_seq = wt_emb.clone()\n",
    "        wt_aa = wt_emb[:, aa_index, :]\n",
    "        print('wt_aa shape: ', wt_aa.shape)\n",
    "        wt = wt_aa.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        mt_embedding_repr =model(mt_input_ids, attention_mask=mt_attention_mask)\n",
    "        mt_emb = mt_embedding_repr.last_hidden_state[:, :s_len]\n",
    "        mt_seq = mt_emb.clone()\n",
    "        mt_aa = mt_emb[:, aa_index, :]\n",
    "        mt = mt_aa.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        aa_emb.append({'wt':wt.reshape(1,-1),'mt':mt.reshape(1,-1), 'label':label})\n",
    "        seq_emb.append({'wt_seq':wt_seq.reshape(1,-1),'mt_seq':mt_seq.reshape(1,-1), 'label':label})\n",
    "\n",
    "# Save results\n",
    "#     if not os.path.isdir(f'{save_path}'):\n",
    "#         os.mkdir(f'{save_path}')\n",
    "\n",
    "#     if start is None:\n",
    "#         # result.to_csv(f'{save_path}/emb_({data_len}).csv', index=False)\n",
    "#         with open(f'{save_path}/emb({data_len}).pkl', 'wb') as f:\n",
    "#             pickle.dump(xs, f)\n",
    "#     else:\n",
    "#         # result.to_csv(f'{save_path}/emb_{stop}.pkl.csv', index=False)\n",
    "#         with open(f'{save_path}/emb_{stop}.pkl', 'wb') as f:\n",
    "#             pickle.dump(xs, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad3cac00-f8fe-4258-b4ce-4d864a36e085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9df0cb-c7c8-40f9-8529-60a854b4c69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5084f-d87b-4502-8671-040806d75565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de90893b-dd0d-460b-9018-36a42564ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a881bcbd-2427-4210-a20e-410a5282ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq = pd.read_csv('../data/mode1_for_embed.csv')\n",
    "# add space between each amino aicds\n",
    "protein_seq['wt_seq'] = protein_seq['wt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))\n",
    "protein_seq['mt_seq'] = protein_seq['mt_seq'].apply(lambda x: ' '.join(x)).apply(\n",
    "        lambda x: re.sub(r\"[UZOB]\", \"X\", x))\n",
    "neutral_df = protein_seq[protein_seq['label']==0]\n",
    "pathogenic_df = protein_seq[protein_seq['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "084b14d8-eb5c-4cab-8e00-8f7d3a68515f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>aa_index</th>\n",
       "      <th>Length</th>\n",
       "      <th>wt</th>\n",
       "      <th>mt</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NP_689699.2</td>\n",
       "      <td>56</td>\n",
       "      <td>681</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NP_689699.2</td>\n",
       "      <td>665</td>\n",
       "      <td>681</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>M S K G I L Q V H P P I C D C P G C R I S S P ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NP_056473.3</td>\n",
       "      <td>203</td>\n",
       "      <td>749</td>\n",
       "      <td>A</td>\n",
       "      <td>V</td>\n",
       "      <td>M A A A G S R K R R L A E L T V D E F L A S G ...</td>\n",
       "      <td>M A A A G S R K R R L A E L T V D E F L A S G ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NP_001354481.1</td>\n",
       "      <td>358</td>\n",
       "      <td>623</td>\n",
       "      <td>G</td>\n",
       "      <td>D</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NP_001354481.1</td>\n",
       "      <td>494</td>\n",
       "      <td>623</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>M G N S H C V P Q A P R R L R A S F S R K P S ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27693</th>\n",
       "      <td>72408</td>\n",
       "      <td>NP_000123.1</td>\n",
       "      <td>795</td>\n",
       "      <td>2351</td>\n",
       "      <td>R</td>\n",
       "      <td>G</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27714</th>\n",
       "      <td>72429</td>\n",
       "      <td>NP_000123.1</td>\n",
       "      <td>503</td>\n",
       "      <td>2351</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27717</th>\n",
       "      <td>72432</td>\n",
       "      <td>NP_000123.1</td>\n",
       "      <td>463</td>\n",
       "      <td>2351</td>\n",
       "      <td>H</td>\n",
       "      <td>Y</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>M Q I E L S T C F F L C L L R F C F S A T R R ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>72463</td>\n",
       "      <td>NP_060666.1</td>\n",
       "      <td>235</td>\n",
       "      <td>421</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>M W Y H R L S H L H S R L Q D L L K G G V I Y ...</td>\n",
       "      <td>M W Y H R L S H L H S R L Q D L L K G G V I Y ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27746</th>\n",
       "      <td>72466</td>\n",
       "      <td>NP_002177.2</td>\n",
       "      <td>365</td>\n",
       "      <td>521</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>M G L G R C I W E G W T L E S E A L R R D M G ...</td>\n",
       "      <td>M G L G R C I W E G W T L E S E A L R R D M G ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20655 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         gene_id  aa_index  Length wt mt  \\\n",
       "0               0     NP_689699.2        56     681  G  S   \n",
       "1               1     NP_689699.2       665     681  G  A   \n",
       "2               2     NP_056473.3       203     749  A  V   \n",
       "3               6  NP_001354481.1       358     623  G  D   \n",
       "4               7  NP_001354481.1       494     623  A  T   \n",
       "...           ...             ...       ...     ... .. ..   \n",
       "27693       72408     NP_000123.1       795    2351  R  G   \n",
       "27714       72429     NP_000123.1       503    2351  R  H   \n",
       "27717       72432     NP_000123.1       463    2351  H  Y   \n",
       "27745       72463     NP_060666.1       235     421  T  N   \n",
       "27746       72466     NP_002177.2       365     521  R  H   \n",
       "\n",
       "                                                  wt_seq  \\\n",
       "0      M S K G I L Q V H P P I C D C P G C R I S S P ...   \n",
       "1      M S K G I L Q V H P P I C D C P G C R I S S P ...   \n",
       "2      M A A A G S R K R R L A E L T V D E F L A S G ...   \n",
       "3      M G N S H C V P Q A P R R L R A S F S R K P S ...   \n",
       "4      M G N S H C V P Q A P R R L R A S F S R K P S ...   \n",
       "...                                                  ...   \n",
       "27693  M Q I E L S T C F F L C L L R F C F S A T R R ...   \n",
       "27714  M Q I E L S T C F F L C L L R F C F S A T R R ...   \n",
       "27717  M Q I E L S T C F F L C L L R F C F S A T R R ...   \n",
       "27745  M W Y H R L S H L H S R L Q D L L K G G V I Y ...   \n",
       "27746  M G L G R C I W E G W T L E S E A L R R D M G ...   \n",
       "\n",
       "                                                  mt_seq  label  \n",
       "0      M S K G I L Q V H P P I C D C P G C R I S S P ...      0  \n",
       "1      M S K G I L Q V H P P I C D C P G C R I S S P ...      0  \n",
       "2      M A A A G S R K R R L A E L T V D E F L A S G ...      0  \n",
       "3      M G N S H C V P Q A P R R L R A S F S R K P S ...      0  \n",
       "4      M G N S H C V P Q A P R R L R A S F S R K P S ...      0  \n",
       "...                                                  ...    ...  \n",
       "27693  M Q I E L S T C F F L C L L R F C F S A T R R ...      0  \n",
       "27714  M Q I E L S T C F F L C L L R F C F S A T R R ...      0  \n",
       "27717  M Q I E L S T C F F L C L L R F C F S A T R R ...      0  \n",
       "27745  M W Y H R L S H L H S R L Q D L L K G G V I Y ...      0  \n",
       "27746  M G L G R C I W E G W T L E S E A L R R D M G ...      0  \n",
       "\n",
       "[20655 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "215564ac-1fc3-49a8-b3e6-2cf2dea74572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>aa_index</th>\n",
       "      <th>Length</th>\n",
       "      <th>wt</th>\n",
       "      <th>mt</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>16301</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>401</td>\n",
       "      <td>445</td>\n",
       "      <td>E</td>\n",
       "      <td>Q</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>16303</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>368</td>\n",
       "      <td>445</td>\n",
       "      <td>M</td>\n",
       "      <td>V</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>16304</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>360</td>\n",
       "      <td>445</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>16307</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>300</td>\n",
       "      <td>445</td>\n",
       "      <td>V</td>\n",
       "      <td>G</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>16308</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>270</td>\n",
       "      <td>445</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>16309</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>230</td>\n",
       "      <td>445</td>\n",
       "      <td>P</td>\n",
       "      <td>S</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>16310</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>225</td>\n",
       "      <td>445</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>16311</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>161</td>\n",
       "      <td>445</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>16312</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>122</td>\n",
       "      <td>445</td>\n",
       "      <td>A</td>\n",
       "      <td>V</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>16313</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>120</td>\n",
       "      <td>445</td>\n",
       "      <td>C</td>\n",
       "      <td>W</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>16317</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>63</td>\n",
       "      <td>445</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>16318</td>\n",
       "      <td>NP_000178.2</td>\n",
       "      <td>53</td>\n",
       "      <td>445</td>\n",
       "      <td>R</td>\n",
       "      <td>Q</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>M A E L K Y I S G F G N E C S S E D P R C P G ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      gene_id  aa_index  Length wt mt  \\\n",
       "5156       16301  NP_000178.2       401     445  E  Q   \n",
       "5158       16303  NP_000178.2       368     445  M  V   \n",
       "5159       16304  NP_000178.2       360     445  G  R   \n",
       "5162       16307  NP_000178.2       300     445  V  G   \n",
       "5163       16308  NP_000178.2       270     445  G  R   \n",
       "5164       16309  NP_000178.2       230     445  P  S   \n",
       "5165       16310  NP_000178.2       225     445  R  H   \n",
       "5166       16311  NP_000178.2       161     445  G  R   \n",
       "5167       16312  NP_000178.2       122     445  A  V   \n",
       "5168       16313  NP_000178.2       120     445  C  W   \n",
       "5172       16317  NP_000178.2        63     445  R  S   \n",
       "5173       16318  NP_000178.2        53     445  R  Q   \n",
       "\n",
       "                                                 wt_seq  \\\n",
       "5156  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5158  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5159  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5162  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5163  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5164  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5165  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5166  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5167  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5168  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5172  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "5173  M A E L K Y I S G F G N E C S S E D P R C P G ...   \n",
       "\n",
       "                                                 mt_seq  label  \n",
       "5156  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5158  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5159  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5162  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5163  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5164  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5165  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5166  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5167  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5168  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5172  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  \n",
       "5173  M A E L K Y I S G F G N E C S S E D P R C P G ...      1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathogenic_df[pathogenic_df['gene_id'] == 'NP_000178.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c94bde99-4b17-4a5b-a043-58e317f4812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 682, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:01<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 682, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [00:02<00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 750, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# tokenizer = config.tokenizer\n",
    "# model = config.model\n",
    "\n",
    "aa_emb = []\n",
    "seq_emb = []\n",
    "result = None\n",
    "count = 0\n",
    "embed_error_count = 0\n",
    "# protein_seq = protein_seq[start:stop]\n",
    "data_len = len(protein_test)\n",
    "\n",
    "for index, seq in tqdm(protein_test.iterrows(),total=protein_test.shape[0]):\n",
    "    s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "    aa_index = seq['aa_index']\n",
    "    label = seq['label']\n",
    "    wt_aa = seq['wt']\n",
    "    mt_aa = seq['mt']\n",
    "    wt_seq = seq['wt_seq']\n",
    "    mt_seq = seq['mt_seq']\n",
    "    gene_id = seq['gene_id']\n",
    "    # AF_DB = seq['AlphaFoldDB']\n",
    "    # PDB = seq['PDB']\n",
    "    # pathogenicity = seq['pathogenicity']\n",
    "\n",
    "    # add_special_tokens adds extra token at the end of each sequence\n",
    "    # token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_token_encoding = tokenizer.batch_encode_plus([seq['wt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_input_ids      = torch.tensor(wt_token_encoding['input_ids']).to(device)\n",
    "    wt_attention_mask = torch.tensor(wt_token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    mt_token_encoding = tokenizer.batch_encode_plus([seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    mt_input_ids      = torch.tensor(mt_token_encoding['input_ids']).to(device)\n",
    "    mt_attention_mask = torch.tensor(mt_token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "        wt_embedding_repr =model(wt_input_ids, attention_mask=wt_attention_mask)\n",
    "        wt_emb = wt_embedding_repr.last_hidden_state[:, :s_len]\n",
    "        wt_seq = wt_emb.detach().cpu().numpy()\n",
    "        print(wt_seq.shape)\n",
    "\n",
    "\n",
    "        mt_embedding_repr =model(mt_input_ids, attention_mask=mt_attention_mask)\n",
    "        mt_emb = mt_embedding_repr.last_hidden_state[:, :s_len]\n",
    "        mt_seq = mt_emb.detach().cpu().numpy()\n",
    "       \n",
    "        embedding_dict = {'wt_seq':wt_seq,\n",
    "                         'mt_seq':mt_seq, \n",
    "                         'aa_index':aa_index\n",
    "                        }\n",
    "        seq_emb.append(embedding_dict)\n",
    "        # aa_emb.append({'wt':wt.reshape(1,-1),'mt':mt.reshape(1,-1), 'label':label})\n",
    "        # seq_emb.append({'wt_seq':wt_seq,'mt_seq':mt_seq, 'aa_index':aa_index})\n",
    "        \n",
    "#         filename = '../t5_embeds/neutral/'+ gene_id + '_' + wt_aa + str(aa_index) + mt_aa + '.pkl'\n",
    "        \n",
    "#         with open(filename, 'wb') as filehandle:\n",
    "#             pickle.dump(embedding_dict, filehandle)\n",
    "            \n",
    "# Save results\n",
    "#     if not os.path.isdir(f'{save_path}'):\n",
    "#         os.mkdir(f'{save_path}')\n",
    "\n",
    "#     if start is None:\n",
    "#         # result.to_csv(f'{save_path}/emb_({data_len}).csv', index=False)\n",
    "#         with open(f'{save_path}/emb({data_len}).pkl', 'wb') as f:\n",
    "#             pickle.dump(xs, f)\n",
    "#     else:\n",
    "#         # result.to_csv(f'{save_path}/emb_{stop}.pkl.csv', index=False)\n",
    "#         with open(f'{save_path}/emb_{stop}.pkl', 'wb') as f:\n",
    "#             pickle.dump(xs, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f20c06e2-b572-4c3d-bc05-0c4505dd5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_emb[0]['wt_seq'][:,aa_index,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fae07-a75e-4e52-b496-1e8ea33d20c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "056b7c39-1f2e-4656-972a-09230cb89fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_emb[0]['aa_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f6d9d-0f18-4d85-9b56-979879636f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(embedding_dict, output_dir, chain_id):\n",
    "    filename = output_dir + chain_id + '.pickle'\n",
    "    with open(filename, 'wb') as filehandle:\n",
    "        pickle.dump(embedding_dict, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc8fe619-18ce-489e-97b0-f96a259e9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = '../t5_embeds/neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea6099d7-d825-485a-8caa-5be84fc69f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = embed_path + '/'\n",
    "concat = []\n",
    "for pkl in os.listdir(path):\n",
    "    if(\".pkl\" in pkl):\n",
    "        file_path = path + pkl\n",
    "        with open(file_path, 'rb') as file:\n",
    "            y = pickle.load(file)\n",
    "            concat.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad15c7a3-6fe0-4633-a08c-b4a01663a114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wt_seq': array([[[ 0.01025558, -0.10217149,  0.02013365, ...,  0.01055854,\n",
       "           0.2522351 , -0.02920763],\n",
       "         [ 0.07315456,  0.04703049,  0.09239218, ..., -0.09874517,\n",
       "           0.13134111, -0.22873077],\n",
       "         [ 0.13563967,  0.00838286, -0.01346737, ..., -0.02939852,\n",
       "           0.11954609, -0.37139788],\n",
       "         ...,\n",
       "         [-0.20492937, -0.07644842, -0.14209639, ..., -0.01432389,\n",
       "          -0.01909379,  0.05864273],\n",
       "         [ 0.02184598, -0.2073565 ,  0.14557888, ...,  0.01770801,\n",
       "          -0.04518939,  0.01948687],\n",
       "         [ 0.06724052, -0.05059998,  0.09423537, ..., -0.07000535,\n",
       "           0.03879933,  0.00983902]]], dtype=float32),\n",
       " 'mt_seq': array([[[ 0.01401372, -0.10365199,  0.01554876, ...,  0.00934867,\n",
       "           0.250978  , -0.02200917],\n",
       "         [ 0.07283772,  0.04388886,  0.08892835, ..., -0.09372276,\n",
       "           0.1330796 , -0.22846796],\n",
       "         [ 0.13466269,  0.00707363, -0.0135285 , ..., -0.02254376,\n",
       "           0.12361645, -0.36959693],\n",
       "         ...,\n",
       "         [-0.20593928, -0.07623573, -0.14285745, ..., -0.01112738,\n",
       "          -0.01662021,  0.05818158],\n",
       "         [ 0.0249898 , -0.20768934,  0.15360859, ...,  0.0189689 ,\n",
       "          -0.04081665,  0.02410129],\n",
       "         [ 0.06680246, -0.05042943,  0.09416126, ..., -0.07017919,\n",
       "           0.03911012,  0.00903932]]], dtype=float32),\n",
       " 'aa_index': 56}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5336c39-5f37-4766-b773-e6abb4643746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407a00a-65d2-4ec3-853e-fbc8294bc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_downstream(embed_path):\n",
    "    path = embed_path + '/'\n",
    "    concat = []\n",
    "    for pkl in os.listdir(path):\n",
    "        if(\".pkl\" in pkl):\n",
    "            file_path = path + pkl\n",
    "            with open(file_path, 'rb') as file:\n",
    "                y = pickle.load(file)\n",
    "                concat.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11211177-8ddd-4b02-99d9-8a13c71bf080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c5890-093d-4aee-825f-34e2f86935cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_downstream(embed_path):\n",
    "    path = embed_path + '/'\n",
    "    concat = []\n",
    "    for pkl in os.listdir(path):\n",
    "        if(\".pkl\" in pkl):\n",
    "            file_path = path + pkl\n",
    "            with open(file_path, 'rb') as file:\n",
    "                y = pickle.load(file)\n",
    "                concat.append(y)\n",
    "    data_y = []\n",
    "    data_X = []\n",
    "    for i in range(len(concat)):\n",
    "        data_X.append(concat[i]['x'][0])\n",
    "        data_y.append(int(concat[i]['label']))\n",
    "    data_X = np.array(data_X)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d92ab-578e-41ec-aa5f-75920b950d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad0abf-c0fc-48ec-9eca-ecb0ef554b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickler(dir, chain_id):\n",
    "    if '.pickle' not in chain_id:\n",
    "        chain_id += '.pickle'\n",
    "    with open(dir + chain_id, 'rb') as filehandle:\n",
    "        return pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b17e5d-2f02-4d1c-b20e-59d8587bb6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b21d503-754b-46a6-9fa1-f2e47399654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickler(embedding_dict, output_dir, chain_id):\n",
    "    filename = output_dir + chain_id + '.pickle'\n",
    "    with open(filename, 'wb') as filehandle:\n",
    "        pickle.dump(embedding_dict, filehandle)\n",
    "\n",
    "\n",
    "def unpickler(dir, chain_id):\n",
    "    if '.pickle' not in chain_id:\n",
    "        chain_id += '.pickle'\n",
    "    with open(dir + chain_id, 'rb') as filehandle:\n",
    "        return pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a461c-9b81-47c0-89b8-64f6e30a80f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe9f40-929c-443a-a838-a2d5d1758ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5c6a2aa-e934-4e79-9def-c5704e58fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq = pd.read_csv('../data/mode1_for_embed.csv')\n",
    "protein_test = protein_seq[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cc63206-cfa6-4584-93a4-446e9474dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingT5(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f82a7318-74f6-4908-830f-cbc40e43d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_seq, mt_seq, wt_emb, mt_emb = model(protein_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc50c8-2b3f-4640-ad2f-ffcf1a7c4764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115bfc0d-48be-4b5e-864c-029f1e9c7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedder = HuggingT5()\n",
    "df = pd.read_csv('example_df.csv')\n",
    "output_dir = 't5_sequence_embeddings/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "try:\n",
    "    # if running as an array job process one row based on integer passed as argument then quit\n",
    "    args = sys.argv\n",
    "    row_index = int(args[1]) - 1\n",
    "except:\n",
    "    # if not in array-job mode iterate through whole dataset\n",
    "    for i, row in df.iterrows():\n",
    "        wt_seq = row['wt_seq']\n",
    "        mt_seq = row['mt_seq']\n",
    "        \n",
    "        wt_seq, mt_seq, wt_emb, mt_emb, label = embedder(df)\n",
    "\n",
    "        \n",
    "        embed_dict = {\n",
    "            'wt_sequence': wt_seq,\n",
    "            'wt_embedding': wt_emb,\n",
    "            'mt_sequence': mt_seq,\n",
    "            'mt_embedding':mt_emb,\n",
    "            'label':label\n",
    "            \n",
    "        }\n",
    "        mt_embed_dict = {\n",
    "            'mt_sequence': mt_seq,\n",
    "            'mt_embedding':mt_emb\n",
    "        }\n",
    "        \n",
    "        \n",
    "        pickler(embed_dict, output_dir, chain_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0476e-5324-429e-bd53-2befeb16b205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87793964-7672-4b10-ad17-f52c45840f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:00<00:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [00:01<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# get attention sum \n",
    "\n",
    "xs = []\n",
    "result = None\n",
    "count = 0\n",
    "embed_error_count = 0\n",
    "# protein_seq = protein_seq[start:stop]\n",
    "data_len = len(protein_seq)\n",
    "\n",
    "for index, seq in tqdm(protein_seq.iterrows(), total=protein_seq.shape[0]):\n",
    "    s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "    aa_index = seq['aa_index']\n",
    "    print(aa_index)\n",
    "    label = seq['label']\n",
    "    wt_aa = seq['wt_aa']\n",
    "    mt_aa = seq['mt_aa']\n",
    "    wt_seq = seq['wt_seq'].replace(\" \",'')\n",
    "    mt_seq = seq['mt_seq'].replace(\" \",'')\n",
    "    # AF_DB = seq['AlphaFoldDB']\n",
    "    # PDB = seq['PDB']\n",
    "    # pathogenicity = seq['pathogenicity']\n",
    "\n",
    "    # add_special_tokens adds extra token at the end of each sequence\n",
    "    # token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_token_encoding = tokenizer.batch_encode_plus([seq['wt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    wt_input_ids      = torch.tensor(wt_token_encoding['input_ids']).to(device)\n",
    "    wt_attention_mask = torch.tensor(wt_token_encoding['attention_mask']).to(device)\n",
    "    \n",
    "    mt_token_encoding = tokenizer.batch_encode_plus([seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    mt_input_ids      = torch.tensor(mt_token_encoding['input_ids']).to(device)\n",
    "    mt_attention_mask = torch.tensor(mt_token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "        wt_embedding_repr = model(wt_input_ids, attention_mask=wt_attention_mask, output_attentions = True)\n",
    "        mt_embedding_repr = model(mt_input_ids, attention_mask=mt_attention_mask, output_attentions = True)\n",
    "        # _,attention = embedding_repr\n",
    "        # print(embedding_repr.attentions)\n",
    "        wt_emb = wt_embedding_repr.attentions[23]\n",
    "        wt_emb = torch.sum(wt_emb, dim = 1)\n",
    "        wt_emb = wt_emb.squeeze(0)[:,aa_index]\n",
    "        # wt_emb = F.normalize(wt_emb, p=2, dim=0)\n",
    "        wt_emb = wt_emb.detach().cpu().numpy()\n",
    "        \n",
    "        mt_emb = mt_embedding_repr.attentions[23]\n",
    "        mt_emb = torch.sum(mt_emb, dim = 1)\n",
    "        mt_emb = mt_emb.squeeze(0)[:,aa_index]\n",
    "        # mt_emb = F.normalize(mt_emb, p=2, dim=0)\n",
    "        mt_emb = mt_emb.detach().cpu().numpy()\n",
    "        \n",
    "        # emb = embedding_repr.last_hidden_state\n",
    "        # print('last_hidden_state shape: ', emb.shape)\n",
    "        \n",
    "\n",
    "        # emb = embedding_repr.last_hidden_state[:, :s_len]\n",
    "        # emb = emb[:, aa_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d86166a2-6871-4029-a8f3-5555a518c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = wt_embedding_repr.attentions[23]\n",
    "# test = torch.sum(test, dim = 1)\n",
    "# test = test.squeeze(0)[:,0]\n",
    "# test_norm = F.normalize(test, p=2, dim=0)\n",
    "# # test = test[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97f7df64-d5cd-45b8-bbea-c0aa91dd46ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1160432  0.12775989 0.11045069 0.14577973 0.10858408 0.11537667\n",
      " 0.10975821 0.11394133 0.1444046  0.1745289  0.15099506 0.1781297\n",
      " 0.17844674 0.1390548  0.17012155 0.17209208 0.17086565 0.17177331\n",
      " 0.14033851 0.11473133 0.2172845  0.1175368  0.10900705 0.15641291\n",
      " 0.0896409  0.15674853 0.17854357 0.15464589 0.14511415 0.22579952\n",
      " 0.17321773 0.14685002 0.111662   0.15953174 0.08071574 0.12249468\n",
      " 0.12150023 0.15322736 0.09856017 0.1250483  0.10344736 0.13067184\n",
      " 0.08169708 0.1225986  0.11090991 0.14295068 0.10121445 0.10842209\n",
      " 0.12657428 0.09247285 0.12581694 0.10699578 0.17590865 0.16513535\n",
      " 0.11665752 0.10353215 0.11359414 0.11031148 0.10424143 0.16148742\n",
      " 0.13407706 0.11382663 0.15381092 0.12532783 0.13636453 0.14971527\n",
      " 0.20012227 0.10632914 0.1322632  0.15494633 0.17363763 0.22133395\n",
      " 0.16021797 0.1598051  0.18786612 0.17880848 0.16776389 0.18553206\n",
      " 0.19663599 0.16966838 0.20723915 0.16902375 0.194119   0.19202387\n",
      " 0.25765848 0.18897063 0.22890988 0.25716606 0.27684712 0.2503236\n",
      " 0.24573082 0.25008228 0.30536178 0.2824055  0.2831388  0.27879673\n",
      " 0.23892377 0.31517196 0.31442454 0.3427791  0.37207344 0.3557935\n",
      " 0.4978447  0.46699205 0.4925533  0.41081887 0.5115009  0.5202433\n",
      " 0.91163456 0.6810055  0.6437694  0.93167573 0.50317585 0.8738372\n",
      " 0.7617072  0.5373177  0.43075246 0.2783184  0.4859227  1.2426401\n",
      " 0.48774105 0.30346847 0.29107487 0.39735872 0.54990476 0.4607504\n",
      " 0.35177732 0.37398988 0.29615143 0.33043405 0.30791855 0.37311968\n",
      " 0.3459285  0.3444838  0.30239308 0.28227404 0.26820838 0.2128286\n",
      " 0.24781233 0.21541938 0.24862057 0.16207615 0.17756122 0.2132678\n",
      " 0.12610283 0.14635687 0.21753514 0.1348229  0.1590731  0.1789079\n",
      " 0.16318782 0.17787428 0.20459878 0.13201047 0.10297643 0.1088613\n",
      " 0.10465142 0.11299716 0.12825844 0.09260114 0.12862846 0.12830785\n",
      " 0.1867603  0.09995648 0.11857173 0.1909084  0.10007653 0.14371532\n",
      " 0.12779482 0.16673324 0.09463059 0.11023542 0.10288577 0.20127049]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "print(wt_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25910610-9f15-493c-bfbe-7f74a2d7332b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cosine_similarity(): argument 'x1' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cos_sim \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwt_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmt_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cos_sim)\n",
      "\u001b[0;31mTypeError\u001b[0m: cosine_similarity(): argument 'x1' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "cos_sim = F.cosine_similarity(wt_emb, mt_emb, dim=0)\n",
    "print(cos_sim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce9dede1-cd21-4f04-8a50-5270996b9fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995120167732239\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "wt = wt_emb\n",
    "mt = mt_emb\n",
    "cos_sim = 1 - spatial.distance.cosine(wt, mt)\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5a973dbd-800f-4a3a-a273-db3cef8ca49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = emb.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e901932-5e53-44a1-af33-ea4fdebaa718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([682, 682])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8e2fb-69bb-4e64-bd88-2463333d881c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([682])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28d821a6-98cc-4dd5-afe0-f666ef3446f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "result = None\n",
    "count = 0\n",
    "embed_error_count = 0\n",
    "# protein_seq = protein_seq[start:stop]\n",
    "data_len = len(protein_seq)\n",
    "\n",
    "for index, seq in tqdm(protein_seq.iterrows(), total=protein_seq.shape[0]):\n",
    "    s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "    aa_index = seq['aa_index']\n",
    "    label = seq['label']\n",
    "    wt_aa = seq['wt_aa']\n",
    "    mt_aa = seq['mt_aa']\n",
    "    wt_seq = seq['wt_seq'].replace(\" \",'')\n",
    "    mt_seq = seq['mt_seq'].replace(\" \",'')\n",
    "    # AF_DB = seq['AlphaFoldDB']\n",
    "    # PDB = seq['PDB']\n",
    "    # pathogenicity = seq['pathogenicity']\n",
    "\n",
    "    # add_special_tokens adds extra token at the end of each sequence\n",
    "    token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "    input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "    attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "        embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "        emb = embedding_repr.last_hidden_state[:, :s_len]\n",
    "        emb = emb[:, aa_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db938c4d-ff51-4e72-b752-0e39bd4a08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7bd5bb-c183-4323-baa1-b10bc0626b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05453132, -0.10480957,  0.03223428, ...,  0.0036165 ,\n",
       "         0.07656325, -0.2850541 ],\n",
       "       [-0.11150735, -0.12776607, -0.00843289, ...,  0.006739  ,\n",
       "         0.05970911, -0.1674745 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3654d05f-7d4c-4393-84de-878bebd64bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "cos_sim = F.cosine_similarity(wt_emb, mt_emb, dim=0)\n",
    "print(cos_sim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb8bfd-aab0-46be-8d75-5a31b3d96c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b788eb2-4b8b-4cd7-b788-b20606f04148",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_test = protein_seq[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb0d116e-c362-4fc7-ab95-364c99efcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def get_embedding(protein_seq, start=None, stop=None, save_path=embed_path):\n",
    "    \n",
    "    xs = []\n",
    "    result = None\n",
    "    count = 0\n",
    "    embed_error_count = 0\n",
    "    protein_seq = protein_seq[start:stop]\n",
    "    data_len = len(protein_seq)\n",
    "\n",
    "    for index, seq in tqdm(protein_seq.iterrows(), total=protein_seq.shape[0]):\n",
    "        s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "        aa_index = seq['aa_index']\n",
    "        label = seq['label']\n",
    "        wt_aa = seq['wt_aa']\n",
    "        mt_aa = seq['mt_aa']\n",
    "        wt_seq = seq['wt_seq'].replace(\" \",'')\n",
    "        mt_seq = seq['mt_seq'].replace(\" \",'')\n",
    "        # AF_DB = seq['AlphaFoldDB']\n",
    "        # PDB = seq['PDB']\n",
    "        # pathogenicity = seq['pathogenicity']\n",
    "        \n",
    "        # add_special_tokens adds extra token at the end of each sequence\n",
    "        token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "            embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            emb = embedding_repr.last_hidden_state[:, :s_len]\n",
    "            # emb = emb[:, aa_index, :]\n",
    "            try:\n",
    "                emb = emb[:, aa_index, :]\n",
    "            except:\n",
    "                embed_error_count += 1\n",
    "                print(f'embedding error: index: {index}, aa_index:{aa_index}, aa_length: {s_len} , error_count:{embed_error_count}')\n",
    "                \n",
    "            # print(aa_index)\n",
    "            x = emb.detach().cpu().numpy().squeeze()\n",
    "            # print(x.shape)\n",
    "            # print(x[0, :].tolist())\n",
    "            # print(x.shape)\n",
    "           \n",
    "            temp = pd.DataFrame({\n",
    "                'label':label,\n",
    "                'mutant_index': aa_index,\n",
    "                'wt_aa': wt_aa,\n",
    "                't_aa': mt_aa,\n",
    "                'wt_seq': wt_seq,\n",
    "                'mt_seq': mt_seq,\n",
    "                'wt_emb': [x[0, :].tolist()],\n",
    "                'mt_emb':[x[1,:].tolist()]\n",
    "                # 'AF_DB': AF_DB,\n",
    "                # 'PDB_ID': PDB\n",
    "            })\n",
    "            \n",
    "            if result is None:\n",
    "                result=temp\n",
    "            else:\n",
    "                result = pd.concat([result,temp])\n",
    "\n",
    "            xs.append({'x':x.reshape(1,-1),'label':label})\n",
    "\n",
    "    # Save results\n",
    "    if not os.path.isdir(f'{save_path}'):\n",
    "        os.mkdir(f'{save_path}')\n",
    "            \n",
    "    if start is None:\n",
    "        result.to_csv(f'{save_path}/sequence_embeddings({data_len}).csv', index=False)\n",
    "        with open(f'{save_path}/emb({data_len}).pkl', 'wb') as f:\n",
    "            pickle.dump(xs, f)\n",
    "    else:\n",
    "        result.to_csv(f'{save_path}/sequence_{stop}_embeddings.csv', index=False)\n",
    "        with open(f'{save_path}/emb_{stop}.pkl', 'wb') as f:\n",
    "            pickle.dump(xs, f)\n",
    "    \n",
    "# get_embedding(seq)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c4d9357-4c9b-459f-ad64-e963401f55c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 1/3 [00:01<00:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 2/3 [00:02<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_path = '../data'\n",
    "df = get_embedding(protein_test, save_path = embed_path).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8338292c-1d34-48eb-9038-4ceec42bdf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['wt_emb'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "909857ed-77b9-4605-8104-79fc74bd9289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mutant_index</th>\n",
       "      <th>wt_aa</th>\n",
       "      <th>t_aa</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>wt_emb</th>\n",
       "      <th>mt_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...</td>\n",
       "      <td>MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...</td>\n",
       "      <td>[-0.051906075328588486, 0.030050912871956825, ...</td>\n",
       "      <td>[-0.05973760783672333, 0.01039073709398508, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>665</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...</td>\n",
       "      <td>MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...</td>\n",
       "      <td>[0.09436676651239395, 0.10468544811010361, -0....</td>\n",
       "      <td>[0.015477344393730164, 0.10830564796924591, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>A</td>\n",
       "      <td>V</td>\n",
       "      <td>MAAAGSRKRRLAELTVDEFLASGFDSESESESENSPQAETREAREA...</td>\n",
       "      <td>MAAAGSRKRRLAELTVDEFLASGFDSESESESENSPQAETREAREA...</td>\n",
       "      <td>[0.07445942610502243, -0.0006038720021024346, ...</td>\n",
       "      <td>[0.0457751490175724, 0.019939227029681206, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  mutant_index wt_aa t_aa  \\\n",
       "0      0            56     G    S   \n",
       "0      0           665     G    A   \n",
       "0      0           203     A    V   \n",
       "\n",
       "                                              wt_seq  \\\n",
       "0  MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...   \n",
       "0  MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...   \n",
       "0  MAAAGSRKRRLAELTVDEFLASGFDSESESESENSPQAETREAREA...   \n",
       "\n",
       "                                              mt_seq  \\\n",
       "0  MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...   \n",
       "0  MSKGILQVHPPICDCPGCRISSPVNRGRLADKRTVALPAARNLKKE...   \n",
       "0  MAAAGSRKRRLAELTVDEFLASGFDSESESESENSPQAETREAREA...   \n",
       "\n",
       "                                              wt_emb  \\\n",
       "0  [-0.051906075328588486, 0.030050912871956825, ...   \n",
       "0  [0.09436676651239395, 0.10468544811010361, -0....   \n",
       "0  [0.07445942610502243, -0.0006038720021024346, ...   \n",
       "\n",
       "                                              mt_emb  \n",
       "0  [-0.05973760783672333, 0.01039073709398508, 0....  \n",
       "0  [0.015477344393730164, 0.10830564796924591, -0...  \n",
       "0  [0.0457751490175724, 0.019939227029681206, -0....  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "411e2276-4619-4f0a-83b0-d203453f0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/sequence_embeddings(5).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f73f4072-ad12-4c90-8f03-f87297de0f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mutant_index</th>\n",
       "      <th>wt_aa</th>\n",
       "      <th>t_aa</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>wt_emb</th>\n",
       "      <th>mt_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>MWYHRLSHLHSRLQDLLKGGVIYPALPQPNFKSLLPLAVHWHHTAS...</td>\n",
       "      <td>MWYHRLSHLHSRLQDLLKGGVIYPALPQPNFKSLLPLAVHWHHTAS...</td>\n",
       "      <td>[0.47407856583595276, -0.004357014782726765, 0...</td>\n",
       "      <td>[0.49423736333847046, -0.00948814395815134, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>R</td>\n",
       "      <td>H</td>\n",
       "      <td>MGLGRCIWEGWTLESEALRRDMGTWLLACICICTCVCLGVSVTGEG...</td>\n",
       "      <td>MGLGRCIWEGWTLESEALRRDMGTWLLACICICTCVCLGVSVTGEG...</td>\n",
       "      <td>[0.10706128925085068, -0.019705910235643387, -...</td>\n",
       "      <td>[0.11566520482301712, -0.03639891371130943, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>Y</td>\n",
       "      <td>C</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>[-0.18334175646305084, 0.42542409896850586, -0...</td>\n",
       "      <td>[-0.21863877773284912, 0.39868706464767456, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>[0.09536199271678925, 0.08094870299100876, 0.1...</td>\n",
       "      <td>[0.051270924508571625, 0.04820641875267029, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>I</td>\n",
       "      <td>T</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...</td>\n",
       "      <td>[0.08919508010149002, -0.23834393918514252, -0...</td>\n",
       "      <td>[0.12021289020776749, -0.27279385924339294, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  mutant_index wt_aa t_aa  \\\n",
       "0      0           235     T    N   \n",
       "1      0           365     R    H   \n",
       "2      1           127     Y    C   \n",
       "3      1            76     R    L   \n",
       "4      1            68     I    T   \n",
       "\n",
       "                                              wt_seq  \\\n",
       "0  MWYHRLSHLHSRLQDLLKGGVIYPALPQPNFKSLLPLAVHWHHTAS...   \n",
       "1  MGLGRCIWEGWTLESEALRRDMGTWLLACICICTCVCLGVSVTGEG...   \n",
       "2  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "3  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "4  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "\n",
       "                                              mt_seq  \\\n",
       "0  MWYHRLSHLHSRLQDLLKGGVIYPALPQPNFKSLLPLAVHWHHTAS...   \n",
       "1  MGLGRCIWEGWTLESEALRRDMGTWLLACICICTCVCLGVSVTGEG...   \n",
       "2  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "3  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "4  MQSYASAMLSVFNSDDYSPAVQENIPALRRSSSFLCTESCNSKYQC...   \n",
       "\n",
       "                                              wt_emb  \\\n",
       "0  [0.47407856583595276, -0.004357014782726765, 0...   \n",
       "1  [0.10706128925085068, -0.019705910235643387, -...   \n",
       "2  [-0.18334175646305084, 0.42542409896850586, -0...   \n",
       "3  [0.09536199271678925, 0.08094870299100876, 0.1...   \n",
       "4  [0.08919508010149002, -0.23834393918514252, -0...   \n",
       "\n",
       "                                              mt_emb  \n",
       "0  [0.49423736333847046, -0.00948814395815134, 0....  \n",
       "1  [0.11566520482301712, -0.03639891371130943, 0....  \n",
       "2  [-0.21863877773284912, 0.39868706464767456, 0....  \n",
       "3  [0.051270924508571625, 0.04820641875267029, 0....  \n",
       "4  [0.12021289020776749, -0.27279385924339294, -0...  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a36d63b9-01b1-493c-b30a-49dba17bdb17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m str_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m str_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt_emb\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "str_list = []\n",
    "str_list.append(test_df['wt_emb'][0].strip('[').strip(']').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe24e491-031e-453a-bf29-6bf77c4f1068",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_df\u001b[49m)):\n\u001b[1;32m      3\u001b[0m     wt_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     mt_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for j in range(len(test_df)):\n",
    "    wt_list = []\n",
    "    mt_list = []\n",
    "    wt_list.append(test_df['wt_emb'][j].strip('[').strip(']').split(', '))\n",
    "    mt_list.append(test_df['mt_emb'][j].strip('[').strip(']').split(', '))\n",
    "    wt_float = [float(i) for i in wt_list[0]]\n",
    "    mt_float = [float(i) for i in mt_list[0]]\n",
    "    stack = np.hstack((wt_float,mt_float))\n",
    "    a.append(stack)\n",
    "arr = np.array(a)\n",
    "arr = np.concatenate((arr, np.array(test_df['label']).reshape(-1,1)), axis = 1)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "350ad3b5-49b8-4b13-93d1-80781cc01668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.74078566e-01, -4.35701478e-03,  1.76675133e-02, ...,\n",
       "        -1.14383489e-01, -4.36267525e-01,  0.00000000e+00],\n",
       "       [ 1.07061289e-01, -1.97059102e-02, -2.84917559e-02, ...,\n",
       "         7.81306550e-02,  2.55043417e-01,  0.00000000e+00],\n",
       "       [-1.83341756e-01,  4.25424099e-01, -1.85506679e-02, ...,\n",
       "        -1.51874289e-01,  1.37499069e-06,  1.00000000e+00],\n",
       "       [ 9.53619927e-02,  8.09487030e-02,  1.46531582e-01, ...,\n",
       "         1.78747680e-02,  6.12068363e-03,  1.00000000e+00],\n",
       "       [ 8.91950801e-02, -2.38343939e-01, -1.26406759e-01, ...,\n",
       "         4.66004968e-01, -2.24090338e-01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc420508-a6aa-4a5d-b964-4d028f226df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = '../data/imbalance_same_seq/Embedding_results_csv/mode_1_embeds'\n",
    "data_X, data_y = data_for_downstream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403731e4-b6e4-476b-a96f-747ddc6346e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05190601,  0.0300509 ,  0.18701199, ...,  0.11976019,\n",
       "       -0.10207947, -0.08150594], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf984842-f261-4d66-88cf-8a5dedd6104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/imbalance_same_seq/Embedding_results_csv/model_1_embeds/sequence_embeddings(27750).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "355f27fe-2790-4fe5-895a-d8c39ba40af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 0.04528007  0.02473227 -0.2799072  ... -0.23358242 -0.02248511\\n  0.28593436]'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wt_emb'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5720234e-b138-4b9c-a5fa-9524128a329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = [float(i) for i in str_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee166e1-e750-4c17-bb38-c56da9dec01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a381eb30-f480-4f29-a81d-e665ad64a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(float_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ebfb5aa-dd5d-4961-8f99-852d54afa568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14ce064a-139c-4498-9b42-d70e2e3db63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.051906075328588486"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(str_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40d82e9a-4300-4a10-810b-7e0ee00bf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_in_batch(protein_seq, amount):\n",
    "    value_input = amount\n",
    "    data_len = len(protein_seq)\n",
    "    fold = data_len // value_input\n",
    "    remainder = data_len - data_len % value_input\n",
    "\n",
    "    for i in range(fold):\n",
    "        get_embedding(protein_seq,  start = i* value_input, stop = (i+1)*value_input)\n",
    "    \n",
    "    get_embedding(protein_seq, start = remainder, stop = data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d84589-0e41-4d64-ba2b-2b461c950af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # generate embeddings in bacth\n",
    "    embed_in_batch(protein_seq, 10)\n",
    "\n",
    "    # # generate embeddings in whole\n",
    "    # get_embedding(protein_seq)\n",
    "except Exception as e:\n",
    "    print('Error: ' + str(e))\n",
    "    allDone()\n",
    "finally:\n",
    "    allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cd535eb-0621-4fc4-8bf2-487f705aa13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode_1_test.csv\n",
      "mode_2_train_3.csv\n",
      "mode_2_train_2.csv\n",
      "mode_2_train_1.csv\n",
      "mode_2_test.csv\n",
      "mode_1_train_1.csv\n",
      "mode_1_train_2.csv\n",
      "mode_1_train_3.csv\n"
     ]
    }
   ],
   "source": [
    "embed_path = '../data/imbalance_same_seq/Embedding_results_csv/model_1_embeds'\n",
    "\n",
    "for csv in os.listdir('../data/balanced_same_seq/'):\n",
    "    if ('.csv' in csv):\n",
    "        print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f1091-f279-44ca-b81c-2ce6018996d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbb539e7-9c06-4eda-8bb2-ecc18338c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_1_test = pd.read_csv('../data/balanced_same_seq/mode_1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0265c8-f2e9-4151-bb7f-347560cdc4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt_emb</th>\n",
       "      <th>mt_emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ 0.28979653 -0.08548378  0.25508213 ... -0.02...</td>\n",
       "      <td>[ 0.40497345 -0.06441736  0.2873508  ...  0.07...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ 0.2392044   0.10363419  0.01531088 ... -0.09...</td>\n",
       "      <td>[ 0.23146236  0.10686753  0.03843426 ... -0.08...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.05516514  0.01958648  0.20229368 ... -0.21...</td>\n",
       "      <td>[-0.07178547 -0.00336192  0.25487044 ... -0.23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.37009916  0.008683    0.10970505 ... -0.06...</td>\n",
       "      <td>[-0.35689098  0.03892659  0.077952   ... -0.04...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ 0.02989817  0.31884304 -0.25646332 ... -0.01...</td>\n",
       "      <td>[ 0.01292542  0.2915483  -0.13674647 ... -0.04...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              wt_emb  \\\n",
       "0  [ 0.28979653 -0.08548378  0.25508213 ... -0.02...   \n",
       "1  [ 0.2392044   0.10363419  0.01531088 ... -0.09...   \n",
       "2  [-0.05516514  0.01958648  0.20229368 ... -0.21...   \n",
       "3  [-0.37009916  0.008683    0.10970505 ... -0.06...   \n",
       "4  [ 0.02989817  0.31884304 -0.25646332 ... -0.01...   \n",
       "\n",
       "                                              mt_emb  label  \n",
       "0  [ 0.40497345 -0.06441736  0.2873508  ...  0.07...      0  \n",
       "1  [ 0.23146236  0.10686753  0.03843426 ... -0.08...      1  \n",
       "2  [-0.07178547 -0.00336192  0.25487044 ... -0.23...      1  \n",
       "3  [-0.35689098  0.03892659  0.077952   ... -0.04...      0  \n",
       "4  [ 0.01292542  0.2915483  -0.13674647 ... -0.04...      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20760e35-09f7-4113-9eee-7cc99c97ad17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def get_embedding(protein_seq, save_path):\n",
    "    \n",
    "    xs = []\n",
    "    count = 0\n",
    "    embed_error_count = 0\n",
    "    data_len = len(protein_seq)\n",
    "\n",
    "    for index, seq in tqdm(protein_seq.iterrows(), total=protein_seq.shape[0]):\n",
    "        s_len = len(seq['wt_seq'].replace(\" \",'')) + 1\n",
    "        label = seq['label']\n",
    "        wt_seq = seq['wt_seq'].replace(\" \",'')\n",
    "        mt_seq = seq['mt_seq'].replace(\" \",'')\n",
    "        # AF_DB = seq['AlphaFoldDB']\n",
    "        # PDB = seq['PDB']\n",
    "        # pathogenicity = seq['pathogenicity']\n",
    "        \n",
    "        # add_special_tokens adds extra token at the end of each sequence\n",
    "        token_encoding = tokenizer.batch_encode_plus([seq['wt_seq'], seq['mt_seq']], add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "            embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            emb = embedding_repr.last_hidden_state[:, :s_len]\n",
    "            # emb = emb[:, aa_index, :]\n",
    "            try:\n",
    "                emb = emb[:, aa_index, :]\n",
    "            except:\n",
    "                embed_error_count += 1\n",
    "                print(f'embedding error: index: {index}, aa_index:{aa_index}, aa_length: {s_len} , error_count:{embed_error_count}')\n",
    "                \n",
    "            # print(aa_index)\n",
    "            x = emb.detach().cpu().numpy().squeeze()\n",
    "           \n",
    "            temp = pd.DataFrame({\n",
    "                'label':label,\n",
    "                'mutant_index': aa_index,\n",
    "                'wt_aa': wt_aa,\n",
    "                't_aa': mt_aa,\n",
    "                'wt_seq': wt_seq,\n",
    "                'mt_seq': mt_seq,\n",
    "                'wt_emb': [x[0, :]],\n",
    "                'mt_emb':[x[1,:]],\n",
    "                # 'AF_DB': AF_DB,\n",
    "                # 'PDB_ID': PDB\n",
    "            })\n",
    "            \n",
    "            if result is None:\n",
    "                result=temp\n",
    "            else:\n",
    "                result = pd.concat([result,temp])\n",
    "\n",
    "            xs.append({'gene_id': 'x':x.reshape(1,-1), 'wt_seq': wt_seq, 'mt_seq': mt_seq ,'label':label})\n",
    "            \n",
    "    # Save results\n",
    "    if not os.path.isdir(f'{save_path}'):\n",
    "        os.mkdir(f'{save_path}')\n",
    "            \n",
    "    if start is None:\n",
    "        # result.to_csv(f'{save_path}/sequence_embeddings({data_len}).csv', index=False)\n",
    "        with open(f'./data_test/emb({data_len}).pkl', 'wb') as f:\n",
    "            pickle.dump(xs, f)\n",
    "    else:\n",
    "        # result.to_csv(f'{save_path}/sequence_{stop}_embeddings.csv', index=False)\n",
    "        with open(f'{save_path}/emb_{stop}.pkl', 'wb') as f:\n",
    "            pickle.dump(xs, f)\n",
    "    \n",
    "# get_embedding(seq)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45e98f74-f6f5-40ac-9da2-b9c42dcf6e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mutant_index</th>\n",
       "      <th>wt_aa</th>\n",
       "      <th>t_aa</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>mt_seq</th>\n",
       "      <th>wt_emb</th>\n",
       "      <th>mt_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>123</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>M Q P R S E R P A G R T Q S P E H G S P G P G ...</td>\n",
       "      <td>M Q P R S E R P A G R T Q S P E H G S P G P G ...</td>\n",
       "      <td>[-0.20791069  0.05744875  0.431307   ... -0.22...</td>\n",
       "      <td>[-0.20496441  0.05060612  0.3893946  ... -0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S N S M ...</td>\n",
       "      <td>[-0.05899208 -0.4959501   0.04672551 ...  0.05...</td>\n",
       "      <td>[-0.06410073 -0.5019426   0.09179133 ...  0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>[-0.1296031  -0.0422971  -0.1627439  ...  0.28...</td>\n",
       "      <td>[-0.13209993 -0.04053592 -0.12918288 ...  0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>[-0.32480806  0.16869994 -0.0275444  ... -0.52...</td>\n",
       "      <td>[-0.3464439   0.12891982  0.02962563 ... -0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>164</td>\n",
       "      <td>R</td>\n",
       "      <td>P</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>M G W D L T V K M L A G N E F Q V S L S S S M ...</td>\n",
       "      <td>[-0.05453132 -0.10480957  0.03223428 ...  0.00...</td>\n",
       "      <td>[-0.11150735 -0.12776607 -0.00843289 ...  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>217</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>[-0.02458479 -0.17859626 -0.06197904 ... -0.22...</td>\n",
       "      <td>[ 0.00635099 -0.17698371 -0.00687718 ... -0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>207</td>\n",
       "      <td>V</td>\n",
       "      <td>M</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>[-0.07218366 -0.08828887  0.42139104 ... -0.18...</td>\n",
       "      <td>[-0.05772915 -0.07945231  0.463516   ... -0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>165</td>\n",
       "      <td>I</td>\n",
       "      <td>T</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>[ 0.34089744 -0.03680613  0.17513815 ... -0.16...</td>\n",
       "      <td>[ 0.35381633 -0.04757376  0.11673401 ... -0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>P</td>\n",
       "      <td>L</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>[-0.06020525 -0.06952492 -0.13853367 ...  0.10...</td>\n",
       "      <td>[-0.05828763 -0.07256152 -0.08972525 ...  0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>L</td>\n",
       "      <td>P</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>M C V G A R R L G R G P C A A L L L L G L G L ...</td>\n",
       "      <td>[-0.20321272 -0.07306463  0.21406977 ...  0.07...</td>\n",
       "      <td>[-0.18795833 -0.04739751  0.16771509 ...  0.07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  mutant_index wt_aa t_aa  \\\n",
       "0    0.0           123     N    S   \n",
       "1    0.0            21     S    N   \n",
       "2    0.0            83     S    N   \n",
       "3    0.0           141     G    S   \n",
       "4    0.0           164     R    P   \n",
       "5    0.0           217     A    T   \n",
       "6    0.0           207     V    M   \n",
       "7    0.0           165     I    T   \n",
       "8    0.0           157     P    L   \n",
       "9    0.0            98     L    P   \n",
       "\n",
       "                                              wt_seq  \\\n",
       "0  M Q P R S E R P A G R T Q S P E H G S P G P G ...   \n",
       "1  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "2  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "3  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "4  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "5  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "6  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "7  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "8  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "9  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "\n",
       "                                              mt_seq  \\\n",
       "0  M Q P R S E R P A G R T Q S P E H G S P G P G ...   \n",
       "1  M G W D L T V K M L A G N E F Q V S L S N S M ...   \n",
       "2  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "3  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "4  M G W D L T V K M L A G N E F Q V S L S S S M ...   \n",
       "5  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "6  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "7  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "8  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "9  M C V G A R R L G R G P C A A L L L L G L G L ...   \n",
       "\n",
       "                                              wt_emb  \\\n",
       "0  [-0.20791069  0.05744875  0.431307   ... -0.22...   \n",
       "1  [-0.05899208 -0.4959501   0.04672551 ...  0.05...   \n",
       "2  [-0.1296031  -0.0422971  -0.1627439  ...  0.28...   \n",
       "3  [-0.32480806  0.16869994 -0.0275444  ... -0.52...   \n",
       "4  [-0.05453132 -0.10480957  0.03223428 ...  0.00...   \n",
       "5  [-0.02458479 -0.17859626 -0.06197904 ... -0.22...   \n",
       "6  [-0.07218366 -0.08828887  0.42139104 ... -0.18...   \n",
       "7  [ 0.34089744 -0.03680613  0.17513815 ... -0.16...   \n",
       "8  [-0.06020525 -0.06952492 -0.13853367 ...  0.10...   \n",
       "9  [-0.20321272 -0.07306463  0.21406977 ...  0.07...   \n",
       "\n",
       "                                              mt_emb  \n",
       "0  [-0.20496441  0.05060612  0.3893946  ... -0.21...  \n",
       "1  [-0.06410073 -0.5019426   0.09179133 ...  0.08...  \n",
       "2  [-0.13209993 -0.04053592 -0.12918288 ...  0.29...  \n",
       "3  [-0.3464439   0.12891982  0.02962563 ... -0.49...  \n",
       "4  [-0.11150735 -0.12776607 -0.00843289 ...  0.00...  \n",
       "5  [ 0.00635099 -0.17698371 -0.00687718 ... -0.21...  \n",
       "6  [-0.05772915 -0.07945231  0.463516   ... -0.16...  \n",
       "7  [ 0.35381633 -0.04757376  0.11673401 ... -0.16...  \n",
       "8  [-0.05828763 -0.07256152 -0.08972525 ...  0.10...  \n",
       "9  [-0.18795833 -0.04739751  0.16771509 ...  0.07...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'{embed_path}/sequence_10_embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae10673-8bd9-458c-ae59-d10ec9160d6a",
   "metadata": {},
   "source": [
    "## Read embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "67d30079-18a2-4de2-8807-9c5496751f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = '../data/gene_not_constrain/imbalance_same_seq/Embedding_results_csv/mode_1_embeds'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d0d46d5b-a1d6-42dd-8809-b0c2a4831297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_downstream():\n",
    "    path = embed_path + '/'\n",
    "    concat = []\n",
    "    for pkl in os.listdir(path):\n",
    "        if(\".pkl\" in pkl):\n",
    "            file_path = path + pkl\n",
    "            with open(file_path, 'rb') as file:\n",
    "                y = pickle.load(file)\n",
    "                concat += y\n",
    "    data_y = []\n",
    "    data_X = []\n",
    "    for i in range(len(concat)):\n",
    "        data_X.append(concat[i]['x'][0])\n",
    "        data_y.append(int(concat[i]['label']))\n",
    "    data_X = np.array(data_X)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91cfe9bf-8a55-457b-9ffc-e5c99857ebb0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'emb_19.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read residue_embeddings\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memb_19.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     y_19 \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      6\u001b[0m data_y \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emb_19.pkl'"
     ]
    }
   ],
   "source": [
    "# read residue_embeddings\n",
    "import pickle\n",
    "\n",
    "with open('emb_19.pkl', 'rb') as file:\n",
    "    y_19 = pickle.load(file)\n",
    "data_y = []\n",
    "data_X = []\n",
    "for i in range(len(y)):\n",
    "    data_X.append(y[i]['x'][0])\n",
    "    data_y.append(int(y[i]['label']))\n",
    "# turn residue_enbeddings (tensors) into numpy array\n",
    "data_X = np.array(data_X)\n",
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a7448d2-57d8-4c75-8cd4-c7c9d0acd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = data_for_downstream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "56f7d615-88e2-454f-a78d-a5e411216088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27750, 2048), 27750)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.shape, len(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c883379-4825-445b-923b-31ec6f2f52c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08853678, -0.0639109 , -0.1026528 , ..., -0.09638178,\n",
       "        0.04749429,  0.04319501], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ce07540e-30d5-4dc3-9ec2-237dfd74d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978c28e-7a65-4fb8-9650-90b5a519d6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396cdaa3-e8fc-45f0-9a04-0c1c2f6b8e81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset and Traditional ML method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbf98ba6-7ce4-4aca-864f-b39451ccfc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16952, 1272, 16952, 1272, 2966, 2966)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切分数据集\n",
    "X_train, X_test, y_train, y_test= train_test_split(data_X, data_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=data_y,\n",
    "                                                   random_state=42)\n",
    "# 切分出valid数据集\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test,\n",
    "                                               test_size=0.3,\n",
    "                                               shuffle=True,\n",
    "                                               stratify=y_test,\n",
    "                                               random_state=42)\n",
    "\n",
    "len(X_train), len(X_test),len(y_train),len(y_test), len(X_valid),len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1393c529-ea14-4d77-a45a-48736b3c252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional ML training\n",
    "\n",
    "result_path = './predicted_results'\n",
    "\n",
    "def traditional_model(name, X_train, y_train, X_test, y_test):\n",
    "    model_name = re.search(r\"(.*)(Classifier|Regression)\", str(name))\n",
    "    model_name = model_name.group(1)\n",
    "\n",
    "    name.fit(X_train, y_train)\n",
    "    y_pred = name.predict(X_test)\n",
    "    \n",
    "    report_save(y_test, y_pred, model_name)\n",
    "    \n",
    "def report_save(y_true, y_pred, name, label_names=None, *args, **kv):\n",
    "    result_path = './predicted_results'\n",
    "    # print the classification report here\n",
    "    report = classification_report(y_true, y_pred, target_names=label_names)\n",
    "    print(colored(f'\\n\\t\\t\\t\\t *** {name}_report ***:\\n\\n\\n', 'blue', attrs=['bold']), report)\n",
    "\n",
    "    # create report dataframe\n",
    "    report_for_save = classification_report(y_true, y_pred, target_names=label_names, output_dict=True)\n",
    "    report_csv = pd.DataFrame(report_for_save).transpose()\n",
    "\n",
    "    # style.background_gradient or highlight_max\n",
    "    report_styled = report_csv.style.background_gradient(subset=['precision', 'recall', 'f1-score'])\n",
    "    \n",
    "    # Save results\n",
    "    if not os.path.isdir(f'{result_path}'):\n",
    "        os.mkdir(f'{result_path}')\n",
    "\n",
    "    # export dataframe to .png\n",
    "    dfi.export(report_styled, f'{result_path}/{name}_report.png')\n",
    "\n",
    "    # report_csv.to_csv(f'{name}_report_save.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf4fd87-4d7e-4e18-b432-696fcb37dd0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# xgb = XGBClassifier()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rfc\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgbt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_s, verbose=False)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m y_rfc \u001b[38;5;241m=\u001b[39m rfc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 668\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:745\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    738\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    739\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    740\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    741\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    742\u001b[0m     )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:247\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    246\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    250\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    251\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    252\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    260\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "eval_s = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=0, n_estimators = 10)\n",
    "gbt=GradientBoostingClassifier(random_state=0, n_estimators = 8)\n",
    "# xgb = XGBClassifier()\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "gbt.fit(X_train, y_train)\n",
    "# xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_s, verbose=False)\n",
    "\n",
    "y_rfc = rfc.predict(X_test)\n",
    "y_gbt = gbt.predict(X_test)\n",
    "# y_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83b3aa-5822-416c-a3b4-0c95f31d4525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c9caa2f-4fb2-42b5-be36-8ce129acbb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "\t\t\t\t *** RandomForest_report ***:\n",
      "\n",
      "\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       682\n",
      "           1       0.74      0.62      0.67       590\n",
      "\n",
      "    accuracy                           0.72      1272\n",
      "   macro avg       0.72      0.71      0.72      1272\n",
      "weighted avg       0.72      0.72      0.72      1272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[92974]: Class WebSwapCGLLayer is implemented in both /System/Library/Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/Versions/A/Frameworks/libANGLE-shared.dylib (0x210e01b50) and /Applications/Google Chrome.app/Contents/Frameworks/Google Chrome Framework.framework/Versions/104.0.5112.79/Libraries/libGLESv2.dylib (0x10aa05d08). One of the two will be used. Which one is undefined.\n",
      "[0807/002243.108705:INFO:headless_shell.cc(660)] Written to file /var/folders/yf/b5jj2z454vx8gz_ppz2wrtdc0000gn/T/tmp4uyuei0p/temp.png.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "\t\t\t\t *** GradientBoosting_report ***:\n",
      "\n",
      "\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       682\n",
      "           1       0.71      0.69      0.70       590\n",
      "\n",
      "    accuracy                           0.73      1272\n",
      "   macro avg       0.73      0.72      0.72      1272\n",
      "weighted avg       0.73      0.73      0.73      1272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[93016]: Class WebSwapCGLLayer is implemented in both /System/Library/Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/Versions/A/Frameworks/libANGLE-shared.dylib (0x210e01b50) and /Applications/Google Chrome.app/Contents/Frameworks/Google Chrome Framework.framework/Versions/104.0.5112.79/Libraries/libGLESv2.dylib (0x10a93dd08). One of the two will be used. Which one is undefined.\n",
      "[0807/002350.474261:INFO:headless_shell.cc(660)] Written to file /var/folders/yf/b5jj2z454vx8gz_ppz2wrtdc0000gn/T/tmp2fpk18bw/temp.png.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:23:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[1m\u001b[34m\n",
      "\t\t\t\t *** XGBoost_report ***:\n",
      "\n",
      "\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       682\n",
      "           1       0.77      0.78      0.78       590\n",
      "\n",
      "    accuracy                           0.79      1272\n",
      "   macro avg       0.79      0.79      0.79      1272\n",
      "weighted avg       0.79      0.79      0.79      1272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[93055]: Class WebSwapCGLLayer is implemented in both /System/Library/Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/Versions/A/Frameworks/libANGLE-shared.dylib (0x210e01b50) and /Applications/Google Chrome.app/Contents/Frameworks/Google Chrome Framework.framework/Versions/104.0.5112.79/Libraries/libGLESv2.dylib (0x1082c5d08). One of the two will be used. Which one is undefined.\n",
      "[0807/002447.404936:INFO:headless_shell.cc(660)] Written to file /var/folders/yf/b5jj2z454vx8gz_ppz2wrtdc0000gn/T/tmptwoj0njj/temp.png.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "gbt=GradientBoostingClassifier(random_state=0, n_estimators = 8)\n",
    "traditional_model(rfc,X_train,y_train,X_test,y_test)\n",
    "traditional_model(gbt,X_train,y_train,X_test,y_test)\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "eval_s = [(X_train, y_train), (X_test, y_test)]\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_s, verbose=False)\n",
    "y_xgb = xgb.predict(X_test)\n",
    "report_save(y_test, y_xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "346b9022-6fcc-47fd-8854-f2630fa1a120",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79      1204\n",
      "           1       0.72      0.61      0.66       857\n",
      "\n",
      "    accuracy                           0.74      2061\n",
      "   macro avg       0.74      0.72      0.73      2061\n",
      "weighted avg       0.74      0.74      0.74      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest report\n",
    "report_save(y_test,y_rfc,'RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b97baf1-450b-4d12-8fda-4722fbc680f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      1204\n",
      "           1       0.74      0.55      0.63       857\n",
      "\n",
      "    accuracy                           0.74      2061\n",
      "   macro avg       0.74      0.71      0.71      2061\n",
      "weighted avg       0.74      0.74      0.73      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoosting report\n",
    "report_save(y_test,y_gbt,'GradientBoosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b802357-6269-4929-b13a-068675f85d0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1204\n",
      "           1       0.77      0.73      0.75       857\n",
      "\n",
      "    accuracy                           0.80      2061\n",
      "   macro avg       0.80      0.79      0.79      2061\n",
      "weighted avg       0.80      0.80      0.80      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost report\n",
    "report_save(y_test,y_xgb,'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac1b683-bb35-4349-af3f-57124b89e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e5548-aa0f-4059-a3aa-466abead79f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fbac8-cba7-462d-ba94-d71ecf8fad87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8836ef-d7c9-4b02-a27d-e62ba67f3085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164cc48-d3f5-4b96-a10f-50f62d408bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d8996-2873-42cd-8c30-0e62ba666981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b133943d-c033-4829-a895-9eef00ffcfb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 随机生成蛋白序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b99d1b-1aeb-41cb-9d39-5e0cce5c7260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4576/2460066529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msub_aa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0morigin_aa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maa_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'origin_aa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0morigin_aa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sub_aa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msub_aa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wild_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwild_type_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mutant'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmutant_type_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4576/2460066529.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msub_aa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0morigin_aa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maa_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'origin_aa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0morigin_aa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sub_aa'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msub_aa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wild_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwild_type_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mutant'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmutant_type_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wild_type_seq = []\n",
    "mutant_type_seq = []\n",
    "aa_index = []\n",
    "sub_aa = []\n",
    "origin_aa=[]\n",
    "label = []\n",
    "generate_length = 15000\n",
    "random.seed(55)\n",
    "\n",
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "alphabet = [char for char in alphabet]\n",
    "alphabet_for_mutant = 'ACDEFGHIJKLMNPQRSTVWXY'\n",
    "alphabet_for_mutant = [char for char in alphabet_for_mutant]\n",
    "\n",
    "for length in range(generate_length):\n",
    "    str_list=[random.choice(alphabet) for i in range(random.randint(200,380))]\n",
    "    random_str = \"\".join(str_list)\n",
    "    random_str = re.sub(r\"[UZOB]\", \"X\", random_str)\n",
    "    wild_type_seq.append(random_str)\n",
    "\n",
    "    sequence =[char for char in random_str]\n",
    "    index = random.choice(range(len(sequence)))\n",
    "    replace = random.choice(alphabet_for_mutant)\n",
    "    origin = sequence[index-1]\n",
    "    sequence[index-1] = replace\n",
    "    mutant_seq = ''.join(sequence)\n",
    "    mutant_type_seq.append(mutant_seq)\n",
    "    aa_index.append(index)\n",
    "    sub_aa.append(replace)\n",
    "    origin_aa.append(origin)\n",
    "    label = [random.randint(0,1) for i in range(generate_length)]\n",
    "\n",
    "dict = {'index': aa_index, 'origin_aa': origin_aa,'sub_aa': sub_aa, 'wild_type': wild_type_seq,'mutant':mutant_type_seq, 'label':label}\n",
    "protein_seq = pd.DataFrame(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453eb5d0-d691-4bd9-8502-1cef76457ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protein_seq.to_csv('practise_seq.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d157a1b-765f-4861-a179-6a4c2c26bfd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(protein_seq['wild_type'][0].replace(\" \",''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "565fa6be-aab8-41f2-94c2-60a13fadd8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f944024c-a1a3-4071-869c-af121d0a8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq = protein_seq[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "452588a3-9643-477a-9f82-5b00a510c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_seq.drop(labels=4274, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e94e0a51-090e-4e07-a2ea-c7aca0daebc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                       66\n",
       "origin_aa                                                    D\n",
       "sub_aa                                                       H\n",
       "wild_type    H K M X X M S X F I M J D X E P Y T K L X X Y ...\n",
       "mutant       H K M X X M S X F I M J D X E P Y T K L X X Y ...\n",
       "label                                                        0\n",
       "Name: 4275, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq.iloc[4274]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03d8861c-59a5-4a92-89fb-0f0129b0fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F J S I D Q Q L C Y D Q G X J Q X X X I J X N K N N H W Y F S K K H X I Q X L X Q W A S J M P G P K P T V X X E A X X X K I X X T D A A X W P M K T A R W L D X Q X V H Q D P X X N X X Q K X X M D I V W X M L S I W R X X X X C W X E W E V K D S X R D X X P Y X T K H L G X L W H C J F L K X E X A X X A V Q R A X W R D X K E L F D N G J J A C T S D I Y K P H A Q C S X R H J M A K X C L X X Q X X N Q N G A X R I K E I X C X J M K X X X W G J X E N G E H K I K X F J H S J E F X E V X E D D V J S V X H C T X L F H V E G R X Q M D N N M V R V A M G R X W L Y T M F T T F P M D C H J J A S C E X Q X D D Y I J E S M V L R I E F C X P G N X P X X G N T E M X X J P X G W V H'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq['wild_type'][1242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9233d8-d97a-4d4a-b934-f322418d3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wild_seq = protein_seq['wild_type']\n",
    "mutant_seq = protein_seq['mutant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28bed90-6825-47a3-ab02-538d648b17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "max_seq_len = 380\n",
    "batch_size = 16\n",
    "\n",
    "# # CUDA\n",
    "# USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# # MPS:\n",
    "# USE_MPS = torch.has_mps\n",
    "\n",
    "# if USE_MPS:\n",
    "#     torch.cuda.manual_seed(2020)\n",
    "#     device = torch.device('mps')\n",
    "#     print('Device name: MPS')\n",
    "# else:\n",
    "#     print('No GPU available, using the CPU instead.')\n",
    "#     device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc21fc7-0e7f-4321-b2ba-12f723f67e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "472f3eae-1e59-43ee-9848-7e1c7fa00f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def get_embedding(protein_seq):\n",
    "    \n",
    "    xs = []\n",
    "    result = None\n",
    "    \n",
    "    for index, seq in protein_seq.iterrows():\n",
    "        s_len = len(seq['wild_type'].replace(\" \",'')) + 1\n",
    "        aa_index = seq['index']\n",
    "        label = seq['label']\n",
    "        wt_aa = seq['origin_aa']\n",
    "        mt_aa = seq['sub_aa']\n",
    "        # add_special_tokens adds extra token at the end of each sequence\n",
    "        token_encoding = tokenizer.batch_encode_plus([seq['wild_type'], seq['mutant']], add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "            embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            emb = embedding_repr.last_hidden_state[:, :s_len]\n",
    "            try:\n",
    "                emb = emb[:, aa_index, :]\n",
    "            except:\n",
    "                print ('Error happends in No. {}, aa_index: {}, sequence length: {}'.format(index, aa_index, s_len))\n",
    "            # print(aa_index)\n",
    "            x = emb.detach().cpu().numpy().squeeze()\n",
    "            temp = pd.DataFrame({'label':label,'mutant_index': aa_index,'wt_aa': wt_aa, 't_aa': mt_aa, 'wt_emb': [x[0, :]], 'mt_emb':[x[1,:]]})\n",
    "            if result is None:\n",
    "                result=temp\n",
    "            else:\n",
    "                result = pd.concat([result,temp])\n",
    "\n",
    "            xs.append({'x':x.reshape(1,-1), 'label':label})\n",
    "            \n",
    "    result.to_csv('test_seq.csv', index = None)\n",
    "    with open('emb.pkl', 'wb') as f:\n",
    "        pickle.dump(xs,f)\n",
    "\n",
    "        \n",
    "get_embedding(protein_seq)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64108c2e-c74d-4531-aba9-0c3954c88351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read residue_embeddings\n",
    "with open('emb.pkl', 'rb') as file:\n",
    "    y = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aed33fbb-908a-4fa9-8855-e0e79036eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = []\n",
    "data_X = []\n",
    "for i in range(len(y)):\n",
    "    data_X.append(y[i]['x'][0])\n",
    "    data_y.append(y[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60825d6e-c5de-4642-b5b0-b978f3b83a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2048)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn residue_enbeddings (tensors) into numpy array\n",
    "data_X = np.array(data_X)\n",
    "data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7db5b-9bbc-4311-9525-5eeeb406256f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca308e91-033b-4937-834b-20818fad4635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 300, 4000, 300, 700, 700)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切分数据集\n",
    "X_train, X_test, y_train, y_test= train_test_split(data_X, data_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=data_y,\n",
    "                                                   random_state=42)\n",
    "# 切分出valid数据集\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test,\n",
    "                                               test_size=0.3,\n",
    "                                               shuffle=True,\n",
    "                                               stratify=y_test,\n",
    "                                               random_state=2020)\n",
    "len(X_train), len(X_test),len(y_train),len(y_test), len(X_valid),len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a6113ad-b6fb-4b59-baf2-2f14e3cc5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.50375, 0.5225 , 0.5225 , 0.48875, 0.52   ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l1\", max_iter=8)\n",
    "cross_val_score(sgd, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d10d9120-fafa-4612-b12e-aea2e44fbb80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4576/2581278691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# rf = RandomForestClassifier(max_depth=19,random_state = 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# rf.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# score=cross_val_score(rf,X_test,y_test,cv=5,scoring='f1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(max_depth=19,random_state = 2)\n",
    "# rf.fit(X_train, y_train)\n",
    "# score=cross_val_score(rf,X_test,y_test,cv=5,scoring='f1')\n",
    "# print(score)\n",
    "\n",
    "eval_s = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_s, verbose=False)\n",
    "xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8258d907-4d71-4b32-8b3c-68bb42958f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting xgboost\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e4/ed/8e2a7ae4e856f4887afc0beee897088ed8dbbc1b19b0f49971019939452a/xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
      "\u001b[K     |▊                               | 4.6 MB 59 kB/s eta 0:52:43^C\n",
      "\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b825aa-2201-4039-94b6-6bcb801cd796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cfd305-3d40-453e-bedf-9f1d1794f872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485361b-c825-43f7-aaae-24525d9673c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb72d7-039a-44c5-aedc-8c9c5b6bdbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (sent_id, mask, labels) in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    # if step % 50 == 0 and not step == 0:\n",
    "      # print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the (sent_id, mask, labels) to gpu\n",
    "    sent_id, mask, labels = sent_id.to(device), mask.to(device), labels.to(device)\n",
    "    # bert = bert.to(device)\n",
    "    # print(sent_id)\n",
    "    x=model_bert(sent_id[0:1,:],mask[0:1,:])\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ab8c3-4faf-4d57-a2c3-dfac8aada940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dd22a-7867-4837-9fc6-d1d56d960760",
   "metadata": {},
   "source": [
    "## 练习测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b5a55-4d77-4601-abdc-34424c0507fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Dataprocessing \n",
    "# protein_df.drop(labels=['PDBID','Unnamed: 3','CHAIN'], axis=1, inplace = True)\n",
    "# protein_df['label'] = [random.randint(0,1) for i in range(39)]\n",
    "\n",
    "# # 随机生成蛋白序列\n",
    "# seq = []\n",
    "# alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# alphabet = [char for char in alphabet]\n",
    "\n",
    "# generate_length = 14961\n",
    "\n",
    "# for length in range(generate_length):\n",
    "#     str_list=[random.choice(alphabet) for i in range(random.randint(200,380))]\n",
    "#     random_str=\"\".join(str_list)\n",
    "#     seq.append(random_str)\n",
    "\n",
    "# # 随机生成label\n",
    "# label = [random.randint(0,1) for i in range(generate_length)]\n",
    "\n",
    "# # 新生成的seq 和label 放入新创建的dataframe\n",
    "# psudo_seq = pd.DataFrame({'sequence': seq, 'label':label})\n",
    "\n",
    "# # 把新生成的dataframe 和以前的拼一起\n",
    "# raw_seq = protein_df.append(psudo_seq)\n",
    "\n",
    "# # settle sequences\n",
    "# seq_batch = [seq for seq in raw_seq.sequence]\n",
    "# seq_batch = [seq.replace(\" \", '') for seq in raw_seq.sequence]\n",
    "# # seq_batch = [' '.join(seq) for seq in seq_batch]\n",
    "# # seq_batch = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in seq_batch]\n",
    "\n",
    "# # 清洗完后放入dataframe\n",
    "# protein_seq = pd.DataFrame({'sequence': seq_batch, 'label':raw_seq.label}, index=None).reset_index()\n",
    "\n",
    "# # 随机选择生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6ada1-7203-4ea8-8724-9df98413fe77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 随机选择生成 mutation， 记录mutant index， mutant aa 和mutant_sequence\n",
    "# def mutation(seq):\n",
    "    \n",
    "#     sequence =[char for char in seq]\n",
    "#     index = random.choice(range(len(sequence)))\n",
    "#     replace = random.choice(alphabet)\n",
    "#     sequence[index] = replace\n",
    "#     mutant_seq = ''.join(sequence)\n",
    "\n",
    "#     return index, replace, mutant_seq\n",
    "\n",
    "# # 把生成的mutation 放入dataframe\n",
    "# # for i in range(protein_seq.shape[0]):\n",
    "# #     protein_seq['index'], protein_seq['sub_aa'], protein_seq['mutant'] = protein_seq['sequence'].apply(mutation)[i]\n",
    "\n",
    "# # # 把生成的dataframe 输出成csv\n",
    "# # protein_seq.to_csv('wild_type_mutant_sequence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa4bba-84a7-459b-bf5b-a3b5035f8a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(test_df.shape[0]):\n",
    "#     test_df['index'], test_df['sub_aa'], test_df['mutant'] = test_df['sequence'].apply(mutation)[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d38577ff7b4259968465e83752cc5980b74e44254e1f6e6da1bf78458fc346f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
